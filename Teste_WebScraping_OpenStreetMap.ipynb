{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias para a raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando o site Open Street Map e capturando as rotas pendentes e as rotas finalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "page_content = navegador.page_source\n",
    "site = BeautifulSoup(page_content, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_pending_routes = []\n",
    "list_finished_routes = []\n",
    "list_routes = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        pending_routes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        pending_link_routes = route.find('a')        \n",
    "        list_routes.append([PREFIX_URL_DOWNLOAD+pending_link_routes['href']])\n",
    "        # list_pending_routes.append([PREFIX_URL_DOWNLOAD+pending_link_routes['href']])\n",
    "        print (f\"{pending_routes.text}: {PREFIX_URL_DOWNLOAD+pending_link_routes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        finished_link_routes = route.find('a')        \n",
    "        list_routes.append([PREFIX_URL_DOWNLOAD+finished_link_routes['href']])\n",
    "        # list_finished_routes.append([PREFIX_URL_DOWNLOAD+finished_link_routes['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+finished_link_routes['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_pending_routes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_finished_routes) #--> Verificando a quantidade de registros na lista de rotas pendentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a telas para efetuar os downloads - Renomeando os arquivo adicionando o nome dos usuários - Movendo para a pasta PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in list_routes:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_page_content = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_page_content, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_user_name = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        user_name = tb_user_name.text\n",
    "        user_name = re.sub(r'\\s|\\.|\\(|\\)','_',user_name)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {user_name}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(user_name)\n",
    "\n",
    "    else:\n",
    "        tb_user_name = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        user_name = tb_user_name.text\n",
    "        user_name = re.sub(r'\\s|\\.|\\(|\\)','_',user_name)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {user_name}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(user_name)\n",
    "time.sleep(3)\n",
    "navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        new_name = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, new_name))\n",
    "\n",
    "files_to_rename_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "files_to_rename_gpx\n",
    "\n",
    "for user, file_to_rename_gpx in zip(users, files_to_rename_gpx):\n",
    "    if os.listdir(DOWNLOADS):\n",
    "        old_path = os.path.join(DOWNLOADS, file_to_rename_gpx)        \n",
    "        new_name = f\"{file_to_rename_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "        new_path = os.path.join(DOWNLOADS,new_name)        \n",
    "        #print(new_path)\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "files_to_move_pre_processing = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for file_to_move_pre_processing in files_to_move_pre_processing:\n",
    "    src_path = os.path.join(DOWNLOADS, file_to_move_pre_processing)\n",
    "    dest_path = os.path.join(PRE_PROCESSING, file_to_move_pre_processing)\n",
    "    try:\n",
    "        os.rename(src_path,dest_path)\n",
    "        print(f\"Arquivo '{file_to_move_pre_processing}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{file_to_move_pre_processing}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando de uma só vez - Entendo que essa execução deve se dar de uma única vez, pois pode haver alguma falha no momento de renomear os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781730\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781729\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781728\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781727\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781726\n",
      "PENDING: https://www.openstreetmap.org/user/dragonpilot/traces/9781725\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781724\n",
      "PENDING: https://www.openstreetmap.org/user/dragonpilot/traces/9781723\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781722\n",
      "PENDING: https://www.openstreetmap.org/user/dragonpilot/traces/9781721\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781720\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781719\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781718\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781717\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781716\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781714\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781713\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781712\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781711\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/9781710\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781730'] Usuário: Routes_from_sunnypilot_2023_08_23-dev__HYUNDAI_PALISADE_2020__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781729'] Usuário: Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781728'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781727'] Usuário: Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781726'] Usuário: Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/dragonpilot/traces/9781725'] Usuário: Routes_from_top_0_9_4_Release_-_2023_07_28__TOYOTA_PRIUS_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781724'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_PRIUS_TSS2_2021__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/dragonpilot/traces/9781723'] Usuário: Routes_from_dragonpilot_2023_08_02__TOYOTA_RAV4_HYBRID_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781722'] Usuário: Routes_from_sunnypilot_2023_06_10-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/dragonpilot/traces/9781721'] Usuário: Routes_from_dragonpilot_2023_02_08__TOYOTA_RAV4_HYBRID_2019__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781720'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__JEEP_GRAND_CHEROKEE_V6_2018__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781719'] Usuário: Routes_from_sunnypilot_2023_08_23-dev__HYUNDAI_IONIQ_5_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781718'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781717'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__HONDA_CIVIC_2016__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781716'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__HYUNDAI_IONIQ_5_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781714'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_RAV4_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781713'] Usuário: Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781712'] Usuário: Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781711'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_RAV4_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/9781710'] Usuário: Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__\n",
      "Arquivo '9781726__Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781716__Routes_from_sunnypilot_0_9_4_1-release__HYUNDAI_IONIQ_5_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781717__Routes_from_sunnypilot_0_9_4_1-release__HONDA_CIVIC_2016__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781727__Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781712__Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781713__Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781719__Routes_from_sunnypilot_2023_08_23-dev__HYUNDAI_IONIQ_5_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781714__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_RAV4_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781725__Routes_from_top_0_9_4_Release_-_2023_07_28__TOYOTA_PRIUS_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781722__Routes_from_sunnypilot_2023_06_10-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781711__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_RAV4_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781721__Routes_from_dragonpilot_2023_02_08__TOYOTA_RAV4_HYBRID_2019__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781729__Routes_from_sunnypilot_2022_11_13__HYUNDAI_SANTA_CRUZ_1ST_GEN__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781730__Routes_from_sunnypilot_2023_08_23-dev__HYUNDAI_PALISADE_2020__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781724__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_PRIUS_TSS2_2021__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781720__Routes_from_sunnypilot_0_9_4_1-release__JEEP_GRAND_CHEROKEE_V6_2018__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781710__Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781718__Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781723__Routes_from_dragonpilot_2023_08_02__TOYOTA_RAV4_HYBRID_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n",
      "Arquivo '9781728__Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSING.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "page_content = navegador.page_source\n",
    "site = BeautifulSoup(page_content, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_pending_routes = []\n",
    "list_finished_routes = []\n",
    "list_routes = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        pending_routes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        pending_link_routes = route.find('a')        \n",
    "        list_routes.append([PREFIX_URL_DOWNLOAD+pending_link_routes['href']])\n",
    "        # list_pending_routes.append([PREFIX_URL_DOWNLOAD+pending_link_routes['href']])\n",
    "        print (f\"{pending_routes.text}: {PREFIX_URL_DOWNLOAD+pending_link_routes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        finished_link_routes = route.find('a')        \n",
    "        list_routes.append([PREFIX_URL_DOWNLOAD+finished_link_routes['href']])\n",
    "        # list_finished_routes.append([PREFIX_URL_DOWNLOAD+finished_link_routes['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+finished_link_routes['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_pending_routes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_finished_routes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "\n",
    "## Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "#navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "\n",
    "## Baixando os arquivos \n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in list_routes:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_page_content = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_page_content, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_user_name = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        user_name = tb_user_name.text\n",
    "        user_name = re.sub(r'\\s|\\.|\\(|\\)','_',user_name)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {user_name}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(user_name)\n",
    "\n",
    "    else:\n",
    "        tb_user_name = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        user_name = tb_user_name.text\n",
    "        user_name = re.sub(r'\\s|\\.|\\(|\\)','_',user_name)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {user_name}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(user_name)\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "\n",
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        new_name = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, new_name))\n",
    "\n",
    "files_to_rename_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "files_to_rename_gpx\n",
    "\n",
    "for user, file_to_rename_gpx in zip(users, files_to_rename_gpx):    \n",
    "    old_path = os.path.join(DOWNLOADS, file_to_rename_gpx)        \n",
    "    new_name = f\"{file_to_rename_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "    new_path = os.path.join(DOWNLOADS,new_name)            \n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "\n",
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "files_to_move_pre_processing = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for file_to_move_pre_processing in files_to_move_pre_processing:\n",
    "    src_path = os.path.join(DOWNLOADS, file_to_move_pre_processing)\n",
    "    dest_path = os.path.join(PRE_PROCESSING, file_to_move_pre_processing)\n",
    "    try:\n",
    "        os.rename(src_path,dest_path)\n",
    "        print(f\"Arquivo '{file_to_move_pre_processing}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{file_to_move_pre_processing}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERIFICAR A FORMA DE LER OS ARQUIVOS QUE ESTÃO NA PASTA DE DOWNLOAD - CONVERTER PARA CSV OU PARQUET E APÓS ESSA CONVERSÃO LEVAR PARA O MINIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo arquivos do Bucket - Transformando os arquivos .gpx em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gpxpy\n",
    "# pip install minio\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd\n",
    "import os\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "BRONZE_LAYER = 'bronze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "#print(minioclient.list_buckets())\n",
    "#print(\"Quantidade de Buckets\", len(minioclient.list_buckets()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9781876__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_COROLLA_TSS2_2019__.gpx',\n",
       " '9781724__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_PRIUS_TSS2_2021__.gpx',\n",
       " '9781659__Routes_from_top_0_9_4_Release_-_2023_07_28__TOYOTA_PRIUS_2017__.gpx',\n",
       " '9781416__Routes_from_sunnypilot_0_9_4_1-release__CHEVROLET_BOLT_EUV_2022__.gpx',\n",
       " '9781882__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx',\n",
       " '9781720__Routes_from_sunnypilot_0_9_4_1-release__JEEP_GRAND_CHEROKEE_V6_2018__.gpx',\n",
       " '9781645__Routes_from_sunnypilot_0_9_4_1-release__HYUNDAI_SANTA_FE_2022__.gpx',\n",
       " '9781891__Routes_from_sunnypilot_0_9_4_1-release__HYUNDAI_IONIQ_5_2022__.gpx',\n",
       " '9781658__Routes_from_dragonpilot_2023_08_22__VOLKSWAGEN_SHARAN_2ND_GEN__.gpx',\n",
       " '9781497__Routes_from_sunnypilot_2023_08_23-dev__HONDA_CIVIC_2016__.gpx',\n",
       " '9781492__Routes_from_dragonpilot_2023_02_08__TOYOTA_RAV4_HYBRID_2019__.gpx',\n",
       " '9781498__Routes_from_sunnypilot_0_9_4_1-release__CHRYSLER_PACIFICA_2018__.gpx',\n",
       " '9781425__Routes_from_dragonpilot_2023_02_08__TOYOTA_RAV4_HYBRID_2019__.gpx',\n",
       " '9781653__Routes_from_dragonpilot_2023_02_08__TOYOTA_RAV4_HYBRID_2019__.gpx',\n",
       " '9781710__Routes_from_sunnypilot_2023_08_04-dev__TOYOTA_COROLLA_TSS2_2019__.gpx',\n",
       " '9781506__Routes_from_sunnypilot_2023_08_23-dev__TOYOTA_RAV4_HYBRID_2019__.gpx',\n",
       " '9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx',\n",
       " '9781649__Routes_from_sunnypilot_0_9_4_1-release__HYUNDAI_SANTA_FE_2022__.gpx',\n",
       " '9781489__Routes_from_top_0_9_4_Release_-_2023_07_28__TOYOTA_PRIUS_v_2017__.gpx',\n",
       " '9781431__Routes_from_dragonpilot_2023_08_22__VOLKSWAGEN_SHARAN_2ND_GEN__.gpx',\n",
       " '9781423__Routes_from_top_0_9_4_Release_-_2023_07_28__TOYOTA_PRIUS_v_2017__.gpx',\n",
       " '9781718__Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__.gpx',\n",
       " '9781648__Routes_from_sunnypilot_2023_08_23-dev__TOYOTA_PRIUS_2017__.gpx',\n",
       " '9781723__Routes_from_dragonpilot_2023_08_02__TOYOTA_RAV4_HYBRID_2017__.gpx',\n",
       " '9781433__Routes_from_sunnypilot_0_9_3_1-release__TOYOTA_RAV4_2019__.gpx',\n",
       " '9781728__Routes_from_sunnypilot_0_9_4_1-release__RAM_1500_5TH_GEN__.gpx',\n",
       " '9781879__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_pre_processing = [arquivo for arquivo in os.listdir(PRE_PROCESSING) if arquivo.endswith(\".gpx\")] #--> Listando todos os arquivos da pasta preprocessamento com extensão .gpx\n",
    "files_to_pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao converter o '9781876__Routes_from_sunnypilot_0_9_4_1-release__TOYOTA_COROLLA_TSS2_2019__.gpx': Error parsing XML: no element found: line 3362, column 17.\n"
     ]
    }
   ],
   "source": [
    "## Criando arquivos CSV a partir dos arquivos .gpx, após a criação do CSV o .gpx correspondente é excluído\n",
    "files_to_pre_processing = [arquivo for arquivo in os.listdir(PRE_PROCESSING) if arquivo.endswith(\".gpx\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .gpx\n",
    "\n",
    "for file_to_pre_processing in files_to_pre_processing:\n",
    "    file_path = os.path.join(PRE_PROCESSING, file_to_pre_processing) # --> Crie o caminho completo para o arquivo GPX\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as gpx_file:\n",
    "            gpx = gpxpy.parse(gpx_file)\n",
    "\n",
    "        info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "        for track in gpx.tracks:\n",
    "            for segment in track.segments:\n",
    "                for point in segment.points:\n",
    "                    info_rota.append({\n",
    "                        'latitude': point.latitude,\n",
    "                        'longitude': point.longitude,\n",
    "                        'elevacao' : point.elevation,\n",
    "                        'time_point' : point.time\n",
    "                    })\n",
    "        file_to_pre_processing_csv = file_to_pre_processing.replace('.gpx','')\n",
    "        info_rota_df = pd.DataFrame(info_rota)\n",
    "        info_rota_df.to_csv(f'{PRE_PROCESSING}/{file_to_pre_processing_csv}.csv', index=False)        \n",
    "        os.remove(file_path)    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter o '{file_to_pre_processing}': {e}.\") #--> Exibindo o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_to_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "files_to_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "len(files_to_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos com a extensão .csv saem da pasta PRE_PROCESSING para a primeira camada (bronze) no MinIO\n",
    "#files_to_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "files_to_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "for name_file in files_to_datalake:\n",
    "    local_path = os.path.join(PRE_PROCESSING, name_file)    \n",
    "    if os.path.isfile(local_path):\n",
    "        try:\n",
    "            minioclient.fput_object(BRONZE_LAYER, name_file, local_path)\n",
    "            print(f\"Arquivo {name_file} enviado com sucesso para o bucket.\")\n",
    "            os.remove(local_path) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta download\n",
    "        except S3Error as e:\n",
    "            print(f\"Erro ao enviar o arquivo: {name_file} -> Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRE_PROCESSING/9632214__Routes_from_sunnypilot_2023_08_19-dev__SUBARU_IMPREZA_LIMITED_2019__.gpx', 'r', encoding='utf-8') as gpx_file:\n",
    "    gpx = gpxpy.parse(gpx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx_file = '9632229__Routes_from_sunnypilot_2023_08_19-dev__HYUNDAI_SANTA_FE_2019__.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx_file = str(gpx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gpx_file, 'r', encoding='utf-8') as gpx_file:\n",
    "    gpx = gpxpy.parse(gpx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a quantidade de pontos (lat+lon+ele) em um arquivo arquivo '.gpx' podemos usar get\n",
    "# Documentação: https://pypi.org/project/gpxpy/\n",
    "gpx.get_track_points_no()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a faixa de altitude, a fim de se obter extremos de maior elevação e menor elevação no trajeto percorrido - os valores apresentados são em metros acima do nível do mar\n",
    "gpx.get_elevation_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não endendi para que isso serve\n",
    "gpx.get_uphill_downhill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o nome do criador da rota - Entretanto no nosso caso quando usamos esse comando temos uma informação generica - Foi necessário obter o nome do criador da rota com o WebScraping\n",
    "creator = gpx.creator\n",
    "creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exibir o conteudo do arquivo .gpx em formato xml\n",
    "print(gpx.to_xml()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possivel verificar quantas rotas/trilhas nosso arquivo .gpx possui\n",
    "len(gpx.tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no nosso exemplo acima só temos 1 rota/trilha efetuada, podemos acessar por meio de indice no python, \n",
    "# Nesse caso se passa o valor [0] para ter uma precisão exata da rota em que estamos trabalhando\n",
    "gpx.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos acessar os segmentos da nossa rota/trilha\n",
    "gpx.tracks[0].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos acessar os pontos de dados individuais dentro do nosso gpx acessando a matriz de pontos. Aqui tambem podemo0s ver o nome das propriedades do arquivo como elevation e time\n",
    "gpx.tracks[0].segments[0].points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui acessamos as tres camadas: Track - Segments e Point e o passamos para um array em forma de dicionário. Note que podemos acessar cada atributo. No meu caso estou pegando latitude, Longitude, Elevação e a hora de cada ponto (entenda-se como ponto Lat+Long+Ele)\n",
    "info_rota = []\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            info_rota.append({\n",
    "                'latitude': point.latitude,\n",
    "                'longitude': point.longitude,\n",
    "                'elevacao' : point.elevation,\n",
    "                'time_point' : point.time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo somente os 3 primeiros resultados\n",
    "info_rota[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui podemos transformar essa informação em um dataframe com a biblioteca pandas\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_csv('pandas_info_rota.csv', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_parquet('pd_parquet_info_rota.parquet', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o bucket e transformando os arquivos encontrados lá em DF Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "BRONZE_LAYER = 'bronze'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "#print(minioclient.list_buckets())\n",
    "#print(\"Quantidade de Buckets\", len(minioclient.list_buckets()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_rota_csv = []\n",
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(BRONZE_LAYER) if arquivo_gpx.object_name.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_rota_csv = minioclient.get_object(BRONZE_LAYER, '9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv')\n",
    "rota_csv = blob_rota_csv.data\n",
    "rota_csv = rota_csv.decode(\"ISO-8859-1\")\n",
    "pre_df = StringIO(rota_csv)\n",
    "df = pd.read_csv(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>time_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.897371</td>\n",
       "      <td>121.139635</td>\n",
       "      <td>214.256</td>\n",
       "      <td>2023-08-29 00:34:24.699000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.897365</td>\n",
       "      <td>121.139613</td>\n",
       "      <td>214.281</td>\n",
       "      <td>2023-08-29 00:34:24.799000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.897360</td>\n",
       "      <td>121.139591</td>\n",
       "      <td>214.299</td>\n",
       "      <td>2023-08-29 00:34:24.899000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.897354</td>\n",
       "      <td>121.139569</td>\n",
       "      <td>214.328</td>\n",
       "      <td>2023-08-29 00:34:24.999000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.897348</td>\n",
       "      <td>121.139548</td>\n",
       "      <td>214.329</td>\n",
       "      <td>2023-08-29 00:34:25.099000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  elevacao                        time_point\n",
       "0  24.897371  121.139635   214.256  2023-08-29 00:34:24.699000+00:00\n",
       "1  24.897365  121.139613   214.281  2023-08-29 00:34:24.799000+00:00\n",
       "2  24.897360  121.139591   214.299  2023-08-29 00:34:24.899000+00:00\n",
       "3  24.897354  121.139569   214.328  2023-08-29 00:34:24.999000+00:00\n",
       "4  24.897348  121.139548   214.329  2023-08-29 00:34:25.099000+00:00"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.897371</td>\n",
       "      <td>121.139635</td>\n",
       "      <td>214.256</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.897365</td>\n",
       "      <td>121.139613</td>\n",
       "      <td>214.281</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.897360</td>\n",
       "      <td>121.139591</td>\n",
       "      <td>214.299</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.897354</td>\n",
       "      <td>121.139569</td>\n",
       "      <td>214.328</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.897348</td>\n",
       "      <td>121.139548</td>\n",
       "      <td>214.329</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  elevacao        data      hora\n",
       "0  24.897371  121.139635   214.256  2023-08-29  00:34:24\n",
       "1  24.897365  121.139613   214.281  2023-08-29  00:34:24\n",
       "2  24.897360  121.139591   214.299  2023-08-29  00:34:24\n",
       "3  24.897354  121.139569   214.328  2023-08-29  00:34:24\n",
       "4  24.897348  121.139548   214.329  2023-08-29  00:34:25"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: 9781892 - username: HONDA_ACCORD_2018\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text = \"9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx\"\n",
    "\n",
    "# Definindo o padrão de regex\n",
    "pattern = r'(.*?)__'\n",
    "\n",
    "# Encontrando todas as correspondências no texto\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Extraindo o nome do carro\n",
    "username = matches[-1]\n",
    "id = matches[0]\n",
    "\n",
    "print(f'Id: {id} - username: {username}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = repeated_id\n",
    "df['username'] = repeated_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781892</td>\n",
       "      <td>HONDA_ACCORD_2018</td>\n",
       "      <td>24.897371</td>\n",
       "      <td>121.139635</td>\n",
       "      <td>214.256</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781892</td>\n",
       "      <td>HONDA_ACCORD_2018</td>\n",
       "      <td>24.897365</td>\n",
       "      <td>121.139613</td>\n",
       "      <td>214.281</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781892</td>\n",
       "      <td>HONDA_ACCORD_2018</td>\n",
       "      <td>24.897360</td>\n",
       "      <td>121.139591</td>\n",
       "      <td>214.299</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781892</td>\n",
       "      <td>HONDA_ACCORD_2018</td>\n",
       "      <td>24.897354</td>\n",
       "      <td>121.139569</td>\n",
       "      <td>214.328</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781892</td>\n",
       "      <td>HONDA_ACCORD_2018</td>\n",
       "      <td>24.897348</td>\n",
       "      <td>121.139548</td>\n",
       "      <td>214.329</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           username   latitude   longitude  elevacao        data  \\\n",
       "0  9781892  HONDA_ACCORD_2018  24.897371  121.139635   214.256  2023-08-29   \n",
       "1  9781892  HONDA_ACCORD_2018  24.897365  121.139613   214.281  2023-08-29   \n",
       "2  9781892  HONDA_ACCORD_2018  24.897360  121.139591   214.299  2023-08-29   \n",
       "3  9781892  HONDA_ACCORD_2018  24.897354  121.139569   214.328  2023-08-29   \n",
       "4  9781892  HONDA_ACCORD_2018  24.897348  121.139548   214.329  2023-08-29   \n",
       "\n",
       "       hora  \n",
       "0  00:34:24  \n",
       "1  00:34:24  \n",
       "2  00:34:24  \n",
       "3  00:34:24  \n",
       "4  00:34:25  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos não mais usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta download para a pasta DATALAKE_STAGE\n",
    "\n",
    "# files_to_move = [files for files in os.listdir(DOWNLOADS) if files.endswith(\".gpx\")]\n",
    "# for name_files in files_to_move:\n",
    "#     origin_path = os.path.join(DOWNLOADS, name_files)\n",
    "#     destiny_path = os.path.join(DATALAKE_STAGE, name_files)\n",
    "#     os.rename(origin_path, destiny_path)\n",
    "#     print(f\"Arquivo {name_files} movido para {destiny_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta DATALAKE_STAGE para o bucket MinIO\n",
    "\n",
    "# for item in os.listdir(DATALAKE_STAGE):\n",
    "#     local_path = os.path.join(DATALAKE_STAGE, item)\n",
    "#     print(local_path)\n",
    "# \n",
    "#     if os.path.isfile(local_path):\n",
    "#         try:\n",
    "#             minioclient.fput_object(DATA_LAKE, item, local_path)\n",
    "#             print(f\"Arquivo {item} enviado com sucesso para o bucket.\")\n",
    "#         except S3Error as err:\n",
    "#             print(f\"Erro ao enviar o arquivo {item}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DADOS PARA INSERIR NA TABELA DE CONTROLE USANDO O BEAUTIFULSOAP ## #\n",
    "# navegador = requests.get('https://www.openstreetmap.org/user/sunnypilot/traces/9255974')\n",
    "# site = BeautifulSoup(navegador.text, 'html.parser')\n",
    "# data_trace = site.find('div', attrs={'class': 'content-body'})\n",
    "# table_trace = data_trace.find('table')\n",
    "# \n",
    "# filename_row = table_trace.find('th', string='Filename:').parent\n",
    "# owner_row = table_trace.find('th', string='Owner:').parent\n",
    "# uploaded_row = table_trace.find('th', string='Uploaded:').parent\n",
    "# \n",
    "# filename = filename_row.find('td').text.strip().replace('(download)','').strip()\n",
    "# owner = owner_row.find('td').text.strip()\n",
    "# uploaded = uploaded_row.find('td').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ESTE TRECHO TEM A FINALIDADE DE BAIXAR OS ARQUIVOS ## #\n",
    "#list_finished_routes\n",
    "#list_pending_routes\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td - finalizado\n",
    "# //*[@id=\"content\"]/div[2]/div/span = PENDENTE\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td - pendente\n",
    "\n",
    "# ## Trecho descontinuado -- Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "# navegador = webdriver.Chrome(service=servico)\n",
    "# for list_route in list_routes:\n",
    "#     sleep(3)\n",
    "#     url = list_route[0]\n",
    "#     navegador.get(url)  #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "#     navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "# navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# # Criando as variáveis que serão utilizadas no Spark\n",
    "# appname = 'tcc-project'\n",
    "# master = 'local'\n",
    "\n",
    "# # Criando a sessão Spark\n",
    "# spark = SparkSession.builder\\\n",
    "#     .appName(appname)\\\n",
    "#     .master(master)\\\n",
    "#     .getOrCreate()\n",
    "# \n",
    "# spark\n",
    "\n",
    "\n",
    "# # Coalesce o DataFrame para um único arquivo\n",
    "# df_single_file = df.coalesce(1)\n",
    "# # Salve o DataFrame coalesced como um único arquivo CSV\n",
    "# df_single_file.write.csv(csv_file_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# Dessa forma o spark gera um csv particionado\n",
    "# df.write.csv('pyspark_dataframe.csv', header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
