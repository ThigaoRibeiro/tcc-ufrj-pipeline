{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias para a raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando o site Open Street Map e capturando as rotas pendentes e as rotas finalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_rotas_pendentes = []\n",
    "list_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # list_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # list_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a telas para efetuar os downloads - Renomeando os arquivo adicionando o nome dos usuários - Movendo para a pasta PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_conteudo_da_pagina = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_conteudo_da_pagina, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "time.sleep(3)\n",
    "navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        novo_nome = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for user, arquivo_para_renomear_gpx in zip(users, arquivos_para_renomear_gpx):\n",
    "    if os.listdir(DOWNLOADS):\n",
    "        caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)        \n",
    "        novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "        caminho_novo = os.path.join(DOWNLOADS,novo_nome)        \n",
    "        #print(caminho_novo)\n",
    "        os.rename(caminho_antigo, caminho_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSING, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ª Função. Responsável por fazer o download das rotas diretamente site, renomear os arquivos e os mover para a pasta de pré processamento - Essa execução deve ser executada de uma única vez, pois pode haver alguma falha no momento de renomear os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIXO_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "rotas = site.findAll('tr')\n",
    "\n",
    "lista_rotas_pendentes = []\n",
    "lista_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for rota in rotas:\n",
    "    if rota.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = rota.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # lista_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # lista_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "\n",
    "## Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "#navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "\n",
    "## Baixando os arquivos \n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "usuarios = []\n",
    "for lista_rota in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = lista_rota[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    conteudo_pagina_download = navegador.page_source\n",
    "    pagina_usuario = BeautifulSoup(conteudo_pagina_download, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in pagina_usuario):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "time.sleep(5)\n",
    "navegador.close()\n",
    "\n",
    "\n",
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "arquivos_para_renomear = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for arquivo_para_renomear in arquivos_para_renomear:\n",
    "        novo_nome = arquivo_para_renomear.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, arquivo_para_renomear), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for usuario, arquivo_para_renomear_gpx in zip(usuarios, arquivos_para_renomear_gpx):        \n",
    "    caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)\n",
    "    novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{usuario}.gpx\"        \n",
    "    caminho_novo = os.path.join(DOWNLOADS,novo_nome)            \n",
    "    os.rename(caminho_antigo, caminho_novo)\n",
    "\n",
    "\n",
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSAMENTO, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSAMENTO}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ª Função - Lendo arquivos pasta de Pré Processamento - Convertendo os arquivos .gpx em .csv - Levando os arquivos .csv para a camada bronze do datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gpxpy\n",
    "# pip install minio\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd\n",
    "import os\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "#print(minioclient.list_buckets())\n",
    "#print(\"Quantidade de Buckets\", len(minioclient.list_buckets()))\n",
    "\n",
    "\n",
    "## Criando arquivos CSV a partir dos arquivos .gpx, após a criação do CSV o .gpx correspondente é excluído\n",
    "arquivos_pre_processamento = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".gpx\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .gpx\n",
    "for arquivo_pre_processamento in arquivos_pre_processamento:\n",
    "    caminho_arquivo = os.path.join(PRE_PROCESSAMENTO, arquivo_pre_processamento) # --> Crie o caminho completo para o arquivo GPX\n",
    "\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "            gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "        info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "        for trilha in gpx.tracks:\n",
    "            for segmento in trilha.segments:\n",
    "                for ponto in segmento.points:\n",
    "                    info_rota.append({\n",
    "                        'latitude': ponto.latitude,\n",
    "                        'longitude': ponto.longitude,\n",
    "                        'elevacao' : ponto.elevation,\n",
    "                        'time_point' : ponto.time\n",
    "                    })\n",
    "        arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv')\n",
    "        info_rota_df = pd.DataFrame(info_rota)\n",
    "        info_rota_df.to_csv(f'{PRE_PROCESSAMENTO}/{arquivo_pre_processamento_csv}', index=False)        \n",
    "        os.remove(caminho_arquivo)    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter o '{arquivo_pre_processamento}': {e}.\") #--> Exibindo o erro\n",
    "        os.remove(caminho_arquivo)\n",
    "        print(f\"Excluindo o arquivo defeituoso: {arquivo_pre_processamento}\")\n",
    "\n",
    "\n",
    "\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .csv\n",
    "for nome_arquivo in arquivos_para_datalake: #--> Iterando sobre cada item da lista\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSAMENTO, nome_arquivo) #--> Criando o caminho completo para o arquivo .csv\n",
    "    if os.path.isfile(caminho_pre_proc): #--> Verificando se o caminho especificado está apontando para um arquivo válido no sistema de arquivos.\n",
    "        try:\n",
    "            minioclient.fput_object(CAMADA_BRONZE, nome_arquivo, caminho_pre_proc) #--> Usando o cliente Minio para enviar o arquivo para o bucket especificado (CAMADA_BRONZE)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\") #--> Exibindo a mensagem de sucesso após o upload dos arquivos para o bucket.\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta PRE_PROCESSAMENTO\n",
    "        except S3Error as e: #--> Capturando qualquer erro que porventura ocorra\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\") #--> Exibindo o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADRAO_REGEX = r'(.*?)__'\n",
    "padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "id_rota = padrao_encontrado[0]\n",
    "nome_usuario = padrao_encontrado[-1]\n",
    "padrao_encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")]\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".parquet\")]\n",
    "len(arquivos_para_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos com a extensão .csv saem da pasta PRE_PROCESSING para a primeira camada (bronze) no MinIO\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "for nome_arquivo in arquivos_para_datalake:\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSING, nome_arquivo)    \n",
    "    if os.path.isfile(caminho_pre_proc):\n",
    "        try:\n",
    "            minioclient.fput_object(BRONZE_LAYER, nome_arquivo, caminho_pre_proc)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\")\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta download\n",
    "        except S3Error as e:\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRE_PROCESSING/9632214__Routes_from_sunnypilot_2023_08_19-dev__SUBARU_IMPREZA_LIMITED_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = '9632229__Routes_from_sunnypilot_2023_08_19-dev__HYUNDAI_SANTA_FE_2019__.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = str(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo_gpx, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a quantidade de pontos (lat+lon+ele) em um arquivo arquivo '.gpx' podemos usar get\n",
    "# Documentação: https://pypi.org/project/gpxpy/\n",
    "gpx.get_track_points_no()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a faixa de altitude, a fim de se obter extremos de maior elevação e menor elevação no trajeto percorrido - os valores apresentados são em metros acima do nível do mar\n",
    "gpx.get_elevation_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não endendi para que isso serve\n",
    "gpx.get_uphill_downhill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o nome do criador da rota - Entretanto no nosso caso quando usamos esse comando temos uma informação generica - Foi necessário obter o nome do criador da rota com o WebScraping\n",
    "creator = gpx.creator\n",
    "creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exibir o conteudo do arquivo .gpx em formato xml\n",
    "print(gpx.to_xml()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possivel verificar quantas rotas/trilhas nosso arquivo .gpx possui\n",
    "len(gpx.tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no nosso exemplo acima só temos 1 rota/trilha efetuada, podemos acessar por meio de indice no python, \n",
    "# Nesse caso se passa o valor [0] para ter uma precisão exata da rota em que estamos trabalhando\n",
    "gpx.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos acessar os segmentos da nossa rota/trilha\n",
    "gpx.tracks[0].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos acessar os pontos de dados individuais dentro do nosso gpx acessando a matriz de pontos. Aqui tambem podemo0s ver o nome das propriedades do arquivo como elevation e time\n",
    "gpx.tracks[0].segments[0].points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui acessamos as tres camadas: Track - Segments e Point e o passamos para um array em forma de dicionário. Note que podemos acessar cada atributo. No meu caso estou pegando latitude, Longitude, Elevação e a hora de cada ponto (entenda-se como ponto Lat+Long+Ele)\n",
    "info_rota = []\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            info_rota.append({\n",
    "                'latitude': point.latitude,\n",
    "                'longitude': point.longitude,\n",
    "                'elevacao' : point.elevation,\n",
    "                'time_point' : point.time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo somente os 3 primeiros resultados\n",
    "info_rota[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui podemos transformar essa informação em um dataframe com a biblioteca pandas\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_csv('pandas_info_rota.csv', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_parquet('pd_parquet_info_rota.parquet', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ª Função - Lendo o bucket e transformando os arquivos encontrados lá em DF Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "CAMADA_SILVER = 'silver'\n",
    "PADRAO_REGEX = r'(.*?)__'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "\n",
    "    ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "    ### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "    df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "    df['data'] = df['time_point'].dt.date\n",
    "    df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "    df = df.drop(columns=['time_point']) \n",
    "\n",
    "    ### USANDO O REGEX PARA PEGAR O ID DA RODA E O NOME DO USUÁRIO (DADOS PRESENTES NO NOME DO ARQUIVO) ###\n",
    "    nome_arquivo = arquivo_rotas_gpx_csv.object_name        \n",
    "    padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "    id_rota = padrao_encontrado[0]\n",
    "    nome_usuario = padrao_encontrado[-1]\n",
    "    num_df = len(df)\n",
    "    replic_id_rota = np.tile(id_rota, num_df)\n",
    "    replic_nome_usuario = np.tile(nome_usuario, num_df)\n",
    "    df['id_rota'] = replic_id_rota\n",
    "    df['nome_usuario'] = replic_nome_usuario\n",
    "    ordenacao_df = ['id_rota', 'nome_usuario', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "    df = df.reindex(columns=ordenacao_df)\n",
    "\n",
    "    try:\n",
    "        csv_bytes = df.to_csv(index=False).encode('utf-8') \n",
    "        csv_buffer = BytesIO(csv_bytes)\n",
    "        minioclient.put_object(\n",
    "                            CAMADA_SILVER,\n",
    "                            nome_arquivo,\n",
    "                            data=csv_buffer,\n",
    "                            length=len(csv_bytes),\n",
    "                            content_type='application/csv')\n",
    "\n",
    "        #minioclient.remove_object(CAMADA_BRONZE, nome_arquivo)        \n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao enviar o arquivo: {nome_arquivo} para a [camada silver]. Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silver/9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destino_csv_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_rota</th>\n",
       "      <th>nome_usuario</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781413</td>\n",
       "      <td>TOYOTA_COROLLA_TSS2_2019</td>\n",
       "      <td>24.897371</td>\n",
       "      <td>121.139635</td>\n",
       "      <td>214.256</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781413</td>\n",
       "      <td>TOYOTA_COROLLA_TSS2_2019</td>\n",
       "      <td>24.897365</td>\n",
       "      <td>121.139613</td>\n",
       "      <td>214.281</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781413</td>\n",
       "      <td>TOYOTA_COROLLA_TSS2_2019</td>\n",
       "      <td>24.897360</td>\n",
       "      <td>121.139591</td>\n",
       "      <td>214.299</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781413</td>\n",
       "      <td>TOYOTA_COROLLA_TSS2_2019</td>\n",
       "      <td>24.897354</td>\n",
       "      <td>121.139569</td>\n",
       "      <td>214.328</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9781413</td>\n",
       "      <td>TOYOTA_COROLLA_TSS2_2019</td>\n",
       "      <td>24.897348</td>\n",
       "      <td>121.139548</td>\n",
       "      <td>214.329</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>00:34:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_rota              nome_usuario   latitude   longitude  elevacao  \\\n",
       "0  9781413  TOYOTA_COROLLA_TSS2_2019  24.897371  121.139635   214.256   \n",
       "1  9781413  TOYOTA_COROLLA_TSS2_2019  24.897365  121.139613   214.281   \n",
       "2  9781413  TOYOTA_COROLLA_TSS2_2019  24.897360  121.139591   214.299   \n",
       "3  9781413  TOYOTA_COROLLA_TSS2_2019  24.897354  121.139569   214.328   \n",
       "4  9781413  TOYOTA_COROLLA_TSS2_2019  24.897348  121.139548   214.329   \n",
       "\n",
       "         data      hora  \n",
       "0  2023-08-29  00:34:24  \n",
       "1  2023-08-29  00:34:24  \n",
       "2  2023-08-29  00:34:24  \n",
       "3  2023-08-29  00:34:24  \n",
       "4  2023-08-29  00:34:25  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_rota_csv = minioclient.get_object(BRONZE_LAYER, '9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv')\n",
    "rota_csv = blob_rota_csv.data\n",
    "rota_csv = rota_csv.decode(\"ISO-8859-1\")\n",
    "pre_df = StringIO(rota_csv)\n",
    "df = pd.read_csv(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text = \"9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx\"\n",
    "\n",
    "# Definindo o padrão de regex\n",
    "pattern = r'(.*?)__'\n",
    "\n",
    "# Encontrando todas as correspondências no texto\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Extraindo o nome do carro\n",
    "username = matches[-1]\n",
    "id = matches[0]\n",
    "\n",
    "print(f'Id: {id} - username: {username}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = repeated_id\n",
    "df['username'] = repeated_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos não mais usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta download para a pasta DATALAKE_STAGE\n",
    "\n",
    "# files_to_move = [files for files in os.listdir(DOWNLOADS) if files.endswith(\".gpx\")]\n",
    "# for nome_arquivos in files_to_move:\n",
    "#     origin_path = os.path.join(DOWNLOADS, nome_arquivos)\n",
    "#     destiny_path = os.path.join(DATALAKE_STAGE, nome_arquivos)\n",
    "#     os.rename(origin_path, destiny_path)\n",
    "#     print(f\"Arquivo {nome_arquivos} movido para {destiny_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta DATALAKE_STAGE para o bucket MinIO\n",
    "\n",
    "# for item in os.listdir(DATALAKE_STAGE):\n",
    "#     caminho_pre_proc = os.path.join(DATALAKE_STAGE, item)\n",
    "#     print(caminho_pre_proc)\n",
    "# \n",
    "#     if os.path.isfile(caminho_pre_proc):\n",
    "#         try:\n",
    "#             minioclient.fput_object(DATA_LAKE, item, caminho_pre_proc)\n",
    "#             print(f\"Arquivo {item} enviado com sucesso para o bucket.\")\n",
    "#         except S3Error as err:\n",
    "#             print(f\"Erro ao enviar o arquivo {item}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DADOS PARA INSERIR NA TABELA DE CONTROLE USANDO O BEAUTIFULSOAP ## #\n",
    "# navegador = requests.get('https://www.openstreetmap.org/user/sunnypilot/traces/9255974')\n",
    "# site = BeautifulSoup(navegador.text, 'html.parser')\n",
    "# data_trace = site.find('div', attrs={'class': 'content-body'})\n",
    "# table_trace = data_trace.find('table')\n",
    "# \n",
    "# filename_row = table_trace.find('th', string='Filename:').parent\n",
    "# owner_row = table_trace.find('th', string='Owner:').parent\n",
    "# uploaded_row = table_trace.find('th', string='Uploaded:').parent\n",
    "# \n",
    "# filename = filename_row.find('td').text.strip().replace('(download)','').strip()\n",
    "# owner = owner_row.find('td').text.strip()\n",
    "# uploaded = uploaded_row.find('td').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ESTE TRECHO TEM A FINALIDADE DE BAIXAR OS ARQUIVOS ## #\n",
    "#list_rotas_finalizadas\n",
    "#list_rotas_pendentes\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td - finalizado\n",
    "# //*[@id=\"content\"]/div[2]/div/span = PENDENTE\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td - pendente\n",
    "\n",
    "# ## Trecho descontinuado -- Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "# navegador = webdriver.Chrome(service=servico)\n",
    "# for list_route in lista_rotas:\n",
    "#     sleep(3)\n",
    "#     url = list_route[0]\n",
    "#     navegador.get(url)  #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "#     navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "# navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n",
    "# Coalesce o DataFrame para um único arquivo\n",
    "df_single_file = df.coalesce(1)\n",
    "# Salve o DataFrame coalesced como um único arquivo CSV\n",
    "df_single_file.write.csv(csv_caminho_arquivo, header=True, mode=\"overwrite\")\n",
    "Dessa forma o spark gera um csv particionado\n",
    "df.write.csv('pyspark_dataframe.csv', header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
