{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias para a raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando o site Open Street Map e capturando as rotas pendentes e as rotas finalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_rotas_pendentes = []\n",
    "list_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # list_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # list_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a telas para efetuar os downloads - Renomeando os arquivo adicionando o nome dos usuários - Movendo para a pasta PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_conteudo_da_pagina = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_conteudo_da_pagina, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "time.sleep(3)\n",
    "navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        novo_nome = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for user, arquivo_para_renomear_gpx in zip(users, arquivos_para_renomear_gpx):\n",
    "    if os.listdir(DOWNLOADS):\n",
    "        caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)        \n",
    "        novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "        caminho_novo = os.path.join(DOWNLOADS,novo_nome)        \n",
    "        #print(caminho_novo)\n",
    "        os.rename(caminho_antigo, caminho_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSING, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ª Função. Responsável por fazer o download das rotas diretamente site, renomear os arquivos e os mover para a pasta de pré processamento - Essa execução deve ser executada de uma única vez, pois pode haver alguma falha no momento de renomear os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENDING: https://www.openstreetmap.org/user/dragonpilot/traces/10086756\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086755\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086754\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086753\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086752\n",
      "PENDING: https://www.openstreetmap.org/user/%D0%9C%D0%B8%D1%85%D0%B0%D0%B8%D0%BB%20%D0%A0%D0%B0%D0%B7%D0%B3%D0%BE%D0%B2%D0%BE%D1%80%D0%BE%D0%B2/traces/10086751\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086749\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086748\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086747\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086746\n",
      "PENDING: https://www.openstreetmap.org/user/%D0%9C%D0%B8%D1%85%D0%B0%D0%B8%D0%BB%20%D0%A0%D0%B0%D0%B7%D0%B3%D0%BE%D0%B2%D0%BE%D1%80%D0%BE%D0%B2/traces/10086745\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086744\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086743\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086742\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086741\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086740\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086739\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086738\n",
      "PENDING: https://www.openstreetmap.org/user/sunnypilot/traces/10086736\n",
      "PENDING: https://www.openstreetmap.org/user/dragonpilot/traces/10086735\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/dragonpilot/traces/10086756'] Usuário: Routes_from_dragonpilot_2023_06_12__TOYOTA_C-HR_HYBRID_2018__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086755'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086754'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086753'] Usuário: Routes_from_sunnypilot_0_9_4_1-release__KIA_NIRO_EV_2020__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086752'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/%D0%9C%D0%B8%D1%85%D0%B0%D0%B8%D0%BB%20%D0%A0%D0%B0%D0%B7%D0%B3%D0%BE%D0%B2%D0%BE%D1%80%D0%BE%D0%B2/traces/10086751'] Usuário: 2023-09-10\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086749'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086748'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086747'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086746'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/%D0%9C%D0%B8%D1%85%D0%B0%D0%B8%D0%BB%20%D0%A0%D0%B0%D0%B7%D0%B3%D0%BE%D0%B2%D0%BE%D1%80%D0%BE%D0%B2/traces/10086745'] Usuário: 2023-07-18-18\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086744'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086743'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086742'] Usuário: Routes_from_sunnypilot_2023_09_08-dev__HONDA_CR-V_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086741'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086740'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086739'] Usuário: Routes_from_sunnypilot_2023_09_08-dev__HONDA_CR-V_2017__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086738'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/sunnypilot/traces/10086736'] Usuário: Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__\n",
      "Rota PENDENTE: ['https://www.openstreetmap.org/user/dragonpilot/traces/10086735'] Usuário: Routes_from_dragonpilot_2023_08_15__TOYOTA_RAV4_HYBRID_2019__\n",
      "Arquivo '10086748__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086742__Routes_from_sunnypilot_2023_09_08-dev__HONDA_CR-V_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086743__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086740__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086738__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086752__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086754__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086746__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086745__2023-07-18-18.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086756__Routes_from_dragonpilot_2023_06_12__TOYOTA_C-HR_HYBRID_2018__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086751__2023-09-10.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086741__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086755__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086749__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086747__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086753__Routes_from_sunnypilot_0_9_4_1-release__KIA_NIRO_EV_2020__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086739__Routes_from_sunnypilot_2023_09_08-dev__HONDA_CR-V_2017__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086735__Routes_from_dragonpilot_2023_08_15__TOYOTA_RAV4_HYBRID_2019__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086736__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n",
      "Arquivo '10086744__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.gpx' movido para a pasta /home/thiago/tcc_ufrj/PRE_PROCESSAMENTO.\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIXO_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "rotas = site.findAll('tr')\n",
    "\n",
    "lista_rotas_pendentes = []\n",
    "lista_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for rota in rotas:\n",
    "    if rota.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = rota.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # lista_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # lista_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "\n",
    "## Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "#navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "\n",
    "## Baixando os arquivos \n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "usuarios = []\n",
    "for lista_rota in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = lista_rota[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    conteudo_pagina_download = navegador.page_source\n",
    "    pagina_usuario = BeautifulSoup(conteudo_pagina_download, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in pagina_usuario):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "time.sleep(5)\n",
    "navegador.close()\n",
    "\n",
    "\n",
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "arquivos_para_renomear = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for arquivo_para_renomear in arquivos_para_renomear:\n",
    "        novo_nome = arquivo_para_renomear.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, arquivo_para_renomear), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for usuario, arquivo_para_renomear_gpx in zip(usuarios, arquivos_para_renomear_gpx):        \n",
    "    caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)\n",
    "    novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{usuario}.gpx\"        \n",
    "    caminho_novo = os.path.join(DOWNLOADS,novo_nome)            \n",
    "    os.rename(caminho_antigo, caminho_novo)\n",
    "\n",
    "\n",
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSAMENTO, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSAMENTO}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ª Função - Lendo arquivos pasta de Pré Processamento - Convertendo os arquivos .gpx em .csv - Levando os arquivos .csv para a camada bronze do datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gpxpy\n",
    "# pip install minio\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd\n",
    "import os\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "#print(minioclient.list_buckets())\n",
    "#print(\"Quantidade de Buckets\", len(minioclient.list_buckets()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando arquivos CSV a partir dos arquivos .gpx, após a criação do CSV o .gpx correspondente é excluído\n",
    "arquivos_pre_processamento = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".gpx\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .gpx\n",
    "for arquivo_pre_processamento in arquivos_pre_processamento:\n",
    "    caminho_arquivo = os.path.join(PRE_PROCESSAMENTO, arquivo_pre_processamento) # --> Crie o caminho completo para o arquivo GPX    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPX(tracks=[GPXTrack(name='2023-09-10T14:40:32.072553', segments=[GPXTrackSegment(points=[...])])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO/10086735__Routes_from_dragonpilot_2023_08_15__TOYOTA_RAV4_HYBRID_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "for trilha in gpx.tracks:\n",
    "    for segmento in trilha.segments:\n",
    "        for ponto in segmento.points:            \n",
    "            #geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "            #latitude = ponto.latitude\n",
    "            #longitude = ponto.longitude\n",
    "\n",
    "            #address = location.raw['address']\n",
    "            #city = address.get('city', '')\n",
    "            #state = address.get('state', '')\n",
    "            #country = address.get('country', '')\n",
    "\n",
    "            #location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "            #address = location.raw['address']\n",
    "            #cidade = address.get('suburb')\n",
    "            #estado = address.get('state')\n",
    "            #pais = address.get('country_code')\n",
    "\n",
    "\n",
    "            info_rota.append({\n",
    "                'latitude': ponto.latitude,\n",
    "                'longitude': ponto.longitude,\n",
    "                'elevacao' : ponto.elevation,\n",
    "                'time_point' : ponto.time\n",
    "                #'cidade': cidade,\n",
    "                #'estado': estado,\n",
    "                #'pais': pais\n",
    "            })\n",
    "arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv')\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.to_csv(f'{PRE_PROCESSAMENTO}/{arquivo_pre_processamento_csv}', index=False)        \n",
    "## os.remove(caminho_arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>time_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.811010</td>\n",
       "      <td>121.200411</td>\n",
       "      <td>274.073</td>\n",
       "      <td>2023-09-10 14:40:32+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.810956</td>\n",
       "      <td>121.200408</td>\n",
       "      <td>274.013</td>\n",
       "      <td>2023-09-10 14:40:32.200000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.810902</td>\n",
       "      <td>121.200405</td>\n",
       "      <td>273.962</td>\n",
       "      <td>2023-09-10 14:40:32.400000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.810875</td>\n",
       "      <td>121.200404</td>\n",
       "      <td>273.956</td>\n",
       "      <td>2023-09-10 14:40:32.500000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.810848</td>\n",
       "      <td>121.200402</td>\n",
       "      <td>273.953</td>\n",
       "      <td>2023-09-10 14:40:32.600000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>24.806944</td>\n",
       "      <td>121.158126</td>\n",
       "      <td>173.124</td>\n",
       "      <td>2023-09-10 14:43:35.200000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>24.806953</td>\n",
       "      <td>121.158066</td>\n",
       "      <td>172.967</td>\n",
       "      <td>2023-09-10 14:43:35.400000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>24.806962</td>\n",
       "      <td>121.158006</td>\n",
       "      <td>172.694</td>\n",
       "      <td>2023-09-10 14:43:35.600000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>24.806971</td>\n",
       "      <td>121.157946</td>\n",
       "      <td>172.501</td>\n",
       "      <td>2023-09-10 14:43:35.800000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>24.806981</td>\n",
       "      <td>121.157886</td>\n",
       "      <td>172.334</td>\n",
       "      <td>2023-09-10 14:43:36+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude   longitude  elevacao                        time_point\n",
       "0     24.811010  121.200411   274.073         2023-09-10 14:40:32+00:00\n",
       "1     24.810956  121.200408   274.013  2023-09-10 14:40:32.200000+00:00\n",
       "2     24.810902  121.200405   273.962  2023-09-10 14:40:32.400000+00:00\n",
       "3     24.810875  121.200404   273.956  2023-09-10 14:40:32.500000+00:00\n",
       "4     24.810848  121.200402   273.953  2023-09-10 14:40:32.600000+00:00\n",
       "...         ...         ...       ...                               ...\n",
       "1495  24.806944  121.158126   173.124  2023-09-10 14:43:35.200000+00:00\n",
       "1496  24.806953  121.158066   172.967  2023-09-10 14:43:35.400000+00:00\n",
       "1497  24.806962  121.158006   172.694  2023-09-10 14:43:35.600000+00:00\n",
       "1498  24.806971  121.157946   172.501  2023-09-10 14:43:35.800000+00:00\n",
       "1499  24.806981  121.157886   172.334         2023-09-10 14:43:36+00:00\n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO/10086744__Routes_from_sunnypilot_2023_08_07-dev__CHEVROLET_BOLT_EUV_2022__.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'], format='%Y-%m-%d %H:%M:%S.%f%z', errors='coerce')\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must be a coordinate pair or Point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/tcc_ufrj/venv/lib/python3.10/site-packages/geopy/geocoders/nominatim.py:350\u001b[0m, in \u001b[0;36mNominatim.reverse\u001b[0;34m(self, query, exactly_one, timeout, language, addressdetails, zoom, namedetails)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     lat, lon \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coerce_point_to_string(query)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/tcc_ufrj/venv/lib/python3.10/site-packages/geopy/geocoders/base.py:300\u001b[0m, in \u001b[0;36mGeocoder._coerce_point_to_string\u001b[0;34m(self, point, output_format)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(point, Point):\n\u001b[0;32m--> 300\u001b[0m     point \u001b[39m=\u001b[39m Point(point)\n\u001b[1;32m    302\u001b[0m \u001b[39m# Altitude is silently dropped.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# Geocoding services (almost?) always consider only lat and lon\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39m# though, because PoIs are assumed to span the whole\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# altitude axis (i.e. not just the 0km plane).\u001b[39;00m\n",
      "File \u001b[0;32m~/tcc_ufrj/venv/lib/python3.10/site-packages/geopy/point.py:166\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[0;34m(cls, latitude, longitude, altitude)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_string(arg)\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/tcc_ufrj/venv/lib/python3.10/site-packages/geopy/point.py:457\u001b[0m, in \u001b[0;36mPoint.from_string\u001b[0;34m(cls, string)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to create Point instance from string: unknown format.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to create Point instance from string: unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb Célula 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m Longitude \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m geolocator \u001b[39m=\u001b[39m Nominatim(user_agent\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgeoapiExercises\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m location \u001b[39m=\u001b[39m geolocator\u001b[39m.\u001b[39;49mreverse(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mLatitude\u001b[39m}\u001b[39;49;00m\u001b[39m,\u001b[39;49m\u001b[39m{\u001b[39;49;00mLongitude\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m address \u001b[39m=\u001b[39m location\u001b[39m.\u001b[39mraw[\u001b[39m'\u001b[39m\u001b[39maddress\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/thiago/tcc_ufrj/Teste_WebScraping_OpenStreetMap.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m cidade \u001b[39m=\u001b[39m address\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msuburb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/tcc_ufrj/venv/lib/python3.10/site-packages/geopy/geocoders/nominatim.py:352\u001b[0m, in \u001b[0;36mNominatim.reverse\u001b[0;34m(self, query, exactly_one, timeout, language, addressdetails, zoom, namedetails)\u001b[0m\n\u001b[1;32m    350\u001b[0m     lat, lon \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coerce_point_to_string(query)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust be a coordinate pair or Point\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m    354\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m: lat,\n\u001b[1;32m    355\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlon\u001b[39m\u001b[39m'\u001b[39m: lon,\n\u001b[1;32m    356\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    357\u001b[0m }\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m language:\n",
      "\u001b[0;31mValueError\u001b[0m: Must be a coordinate pair or Point"
     ]
    }
   ],
   "source": [
    "Latitude = df['latitude']\n",
    "Longitude = df['longitude']\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')\n",
    "\n",
    "estado = estado[-2:]\n",
    "pais = pais.upper()\n",
    "\n",
    "print(f\"Cidade: {cidade}\")\n",
    "print(f\"Estado (abreviado): {estado[-2:]}\")\n",
    "print(f\"País: {pais}\")\n",
    "\n",
    "replic_id_rota = df['id_rota']\n",
    "replic_nome_usuario = df['nome_usuario']\n",
    "#\n",
    "#ordenacao_df = ['id_rota', 'nome_usuario', 'latitude', 'longitude', 'elevacao', 'data', 'hora', 'cidade', 'estado', 'pais']\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Hugh Baldock Freeway, Fargo, Marion County, Oregon, 97002, United States\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "#Latitude = \"45.24559097710776\"\n",
    "#Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Executando de uma unica vez ##\n",
    "# pip install gpxpy\n",
    "# pip install minio\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd\n",
    "import os\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "#print(minioclient.list_buckets())\n",
    "#print(\"Quantidade de Buckets\", len(minioclient.list_buckets()))\n",
    "\n",
    "\n",
    "## Criando arquivos CSV a partir dos arquivos .gpx, após a criação do CSV o .gpx correspondente é excluído\n",
    "arquivos_pre_processamento = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".gpx\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .gpx\n",
    "for arquivo_pre_processamento in arquivos_pre_processamento:\n",
    "    caminho_arquivo = os.path.join(PRE_PROCESSAMENTO, arquivo_pre_processamento) # --> Crie o caminho completo para o arquivo GPX\n",
    "\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "            gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "        info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "        for trilha in gpx.tracks:\n",
    "            for segmento in trilha.segments:\n",
    "                for ponto in segmento.points:\n",
    "                    \n",
    "                    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "                    latitude = ponto.latitude\n",
    "                    longitude = ponto.longitude\n",
    "                    location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "\n",
    "\n",
    "                    address = location.raw['address']\n",
    "                    city = address.get('city', '')\n",
    "                    state = address.get('state', '')\n",
    "                    country = address.get('country', '')\n",
    "\n",
    "                    location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "                    address = location.raw['address']\n",
    "                    cidade = address.get('suburb')\n",
    "                    estado = address.get('state')\n",
    "                    pais = address.get('country_code')\n",
    "\n",
    "\n",
    "                    info_rota.append({\n",
    "                        'latitude': ponto.latitude,\n",
    "                        'longitude': ponto.longitude,\n",
    "                        'elevacao' : ponto.elevation,\n",
    "                        'time_point' : ponto.time,\n",
    "                        'cidade': cidade,\n",
    "                        'estado': estado,\n",
    "                        'pais': pais\n",
    "                    })\n",
    "        arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv')\n",
    "        info_rota_df = pd.DataFrame(info_rota)\n",
    "        info_rota_df.to_csv(f'{PRE_PROCESSAMENTO}/{arquivo_pre_processamento_csv}', index=False)        \n",
    "        os.remove(caminho_arquivo)    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter o '{arquivo_pre_processamento}': {e}.\") #--> Exibindo o erro\n",
    "        os.remove(caminho_arquivo)\n",
    "        print(f\"Excluindo o arquivo defeituoso: {arquivo_pre_processamento}\")\n",
    "\n",
    "\n",
    "\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")] #--> Listando todos os arquivos da pasta pré-processamento com extensão .csv\n",
    "for nome_arquivo in arquivos_para_datalake: #--> Iterando sobre cada item da lista\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSAMENTO, nome_arquivo) #--> Criando o caminho completo para o arquivo .csv\n",
    "    if os.path.isfile(caminho_pre_proc): #--> Verificando se o caminho especificado está apontando para um arquivo válido no sistema de arquivos.\n",
    "        try:\n",
    "            minioclient.fput_object(CAMADA_BRONZE, nome_arquivo, caminho_pre_proc) #--> Usando o cliente Minio para enviar o arquivo para o bucket especificado (CAMADA_BRONZE)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\") #--> Exibindo a mensagem de sucesso após o upload dos arquivos para o bucket.\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta PRE_PROCESSAMENTO\n",
    "        except S3Error as e: #--> Capturando qualquer erro que porventura ocorra\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\") #--> Exibindo o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADRAO_REGEX = r'(.*?)__'\n",
    "padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "id_rota = padrao_encontrado[0]\n",
    "nome_usuario = padrao_encontrado[-1]\n",
    "padrao_encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")]\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".parquet\")]\n",
    "len(arquivos_para_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos com a extensão .csv saem da pasta PRE_PROCESSING para a primeira camada (bronze) no MinIO\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "for nome_arquivo in arquivos_para_datalake:\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSING, nome_arquivo)    \n",
    "    if os.path.isfile(caminho_pre_proc):\n",
    "        try:\n",
    "            minioclient.fput_object(BRONZE_LAYER, nome_arquivo, caminho_pre_proc)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\")\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta download\n",
    "        except S3Error as e:\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRE_PROCESSING/9632214__Routes_from_sunnypilot_2023_08_19-dev__SUBARU_IMPREZA_LIMITED_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = '9632229__Routes_from_sunnypilot_2023_08_19-dev__HYUNDAI_SANTA_FE_2019__.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = str(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo_gpx, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a quantidade de pontos (lat+lon+ele) em um arquivo arquivo '.gpx' podemos usar get\n",
    "# Documentação: https://pypi.org/project/gpxpy/\n",
    "gpx.get_track_points_no()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a faixa de altitude, a fim de se obter extremos de maior elevação e menor elevação no trajeto percorrido - os valores apresentados são em metros acima do nível do mar\n",
    "gpx.get_elevation_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não endendi para que isso serve\n",
    "gpx.get_uphill_downhill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o nome do criador da rota - Entretanto no nosso caso quando usamos esse comando temos uma informação generica - Foi necessário obter o nome do criador da rota com o WebScraping\n",
    "creator = gpx.creator\n",
    "creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exibir o conteudo do arquivo .gpx em formato xml\n",
    "print(gpx.to_xml()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possivel verificar quantas rotas/trilhas nosso arquivo .gpx possui\n",
    "len(gpx.tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no nosso exemplo acima só temos 1 rota/trilha efetuada, podemos acessar por meio de indice no python, \n",
    "# Nesse caso se passa o valor [0] para ter uma precisão exata da rota em que estamos trabalhando\n",
    "gpx.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos acessar os segmentos da nossa rota/trilha\n",
    "gpx.tracks[0].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos acessar os pontos de dados individuais dentro do nosso gpx acessando a matriz de pontos. Aqui tambem podemo0s ver o nome das propriedades do arquivo como elevation e time\n",
    "gpx.tracks[0].segments[0].points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui acessamos as tres camadas: Track - Segments e Point e o passamos para um array em forma de dicionário. Note que podemos acessar cada atributo. No meu caso estou pegando latitude, Longitude, Elevação e a hora de cada ponto (entenda-se como ponto Lat+Long+Ele)\n",
    "info_rota = []\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            info_rota.append({\n",
    "                'latitude': point.latitude,\n",
    "                'longitude': point.longitude,\n",
    "                'elevacao' : point.elevation,\n",
    "                'time_point' : point.time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo somente os 3 primeiros resultados\n",
    "info_rota[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui podemos transformar essa informação em um dataframe com a biblioteca pandas\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_csv('pandas_info_rota.csv', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_parquet('pd_parquet_info_rota.parquet', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ª Função - Lendo o bucket e transformando os arquivos encontrados lá em DF Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "CAMADA_SILVER = 'silver'\n",
    "PADRAO_REGEX = r'(.*?)__'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "    try:\n",
    "\n",
    "        ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "        obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "        csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "        arquivo_csv = StringIO(csv_decod)\n",
    "        df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "        #### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "        df['time_point'] = pd.to_datetime(df['time_point'], format='%Y-%m-%d %H:%M:%S.%f%z', errors='coerce')\n",
    "        df['data'] = df['time_point'].dt.date\n",
    "        df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "        df = df.drop(columns=['time_point'])\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao alterar a data do arquivo: {nome_arquivo}. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "\n",
    "    ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "    ### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "    df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "    df['data'] = df['time_point'].dt.date\n",
    "    df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "    df = df.drop(columns=['time_point']) \n",
    "\n",
    "    ### USANDO O REGEX PARA PEGAR O ID DA RODA E O NOME DO USUÁRIO (DADOS PRESENTES NO NOME DO ARQUIVO) ###\n",
    "    nome_arquivo = arquivo_rotas_gpx_csv.object_name        \n",
    "    padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "    id_rota = padrao_encontrado[0]\n",
    "    nome_usuario = padrao_encontrado[-1]\n",
    "    num_df = len(df)\n",
    "    replic_id_rota = np.tile(id_rota, num_df)\n",
    "    replic_nome_usuario = np.tile(nome_usuario, num_df)\n",
    "    df['id_rota'] = replic_id_rota\n",
    "    df['nome_usuario'] = replic_nome_usuario\n",
    "    ordenacao_df = ['id_rota', 'nome_usuario', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "    df = df.reindex(columns=ordenacao_df)\n",
    "\n",
    "    try:\n",
    "        csv_bytes = df.to_csv(index=False).encode('utf-8') \n",
    "        csv_buffer = BytesIO(csv_bytes)\n",
    "        minioclient.put_object(\n",
    "                            CAMADA_SILVER,\n",
    "                            nome_arquivo,\n",
    "                            data=csv_buffer,\n",
    "                            length=len(csv_bytes),\n",
    "                            content_type='application/csv')\n",
    "\n",
    "        #minioclient.remove_object(CAMADA_BRONZE, nome_arquivo)        \n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao enviar o arquivo: {nome_arquivo} para a [camada silver]. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destino_csv_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_rota_csv = minioclient.get_object(BRONZE_LAYER, '9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv')\n",
    "rota_csv = blob_rota_csv.data\n",
    "rota_csv = rota_csv.decode(\"ISO-8859-1\")\n",
    "pre_df = StringIO(rota_csv)\n",
    "df = pd.read_csv(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text = \"9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx\"\n",
    "\n",
    "# Definindo o padrão de regex\n",
    "pattern = r'(.*?)__'\n",
    "\n",
    "# Encontrando todas as correspondências no texto\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Extraindo o nome do carro\n",
    "username = matches[-1]\n",
    "id = matches[0]\n",
    "\n",
    "print(f'Id: {id} - username: {username}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = repeated_id\n",
    "df['username'] = repeated_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrevendo os arquivos no banco de dados Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2\n",
    "import psycopg2\n",
    "import os\n",
    "from minio import Minio\n",
    "import io\n",
    "\n",
    "CAMADA_SILVER = 'silver'\n",
    "\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "\n",
    "db_config = {\n",
    "'host': 'localhost',\n",
    "'database': 'gold-saint',\n",
    "'user': 'postgres',\n",
    "'password': 'postgres',\n",
    "}\n",
    "\n",
    "copy_sql = \"\"\"\n",
    "    COPY tb_gpx_full (id_rota, nome_usuario, latitude, longitude, elevacao, data_rota, hora_rota)\n",
    "    FROM stdin WITH CSV HEADER DELIMITER as ','\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "if not arquivos_rotas_gpx_csv:\n",
    "    print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "else:\n",
    "    print(f\"Existem {len(arquivos_rotas_gpx_csv)} arquivos no Bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Lista todos os arquivos na camada \"silver\" do Minio que têm extensão .csv\n",
    "    arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "    \n",
    "    # Verifica se há arquivos no bucket antes de continuar\n",
    "    if not arquivos_rotas_gpx_csv:\n",
    "        print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "\n",
    "    else:\n",
    "        # Conexão com o banco de dados PostgreSQL\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Itera sobre cada arquivo CSV encontrado no Minio\n",
    "        for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "            # Obtém o objeto do arquivo CSV do Minio  \n",
    "            obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)            \n",
    "\n",
    "            # Decodifica os dados do arquivo CSV de bytes para string\n",
    "            csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string            \n",
    "\n",
    "            # Usa io.StringIO para criar um objeto de arquivo legível a partir da string CSV\n",
    "            with io.StringIO(csv_decod) as file:        \n",
    "\n",
    "                # Executa o comando COPY para inserir os dados no banco de dados PostgreSQL\n",
    "                cursor.copy_expert(sql=copy_sql, file=file)\n",
    "\n",
    "            # Commit para salvar as alterações no banco de dados    \n",
    "            conn.commit()        \n",
    "\n",
    "            # Remove o arquivo do bucket \"silver\" no Minio após ser processado\n",
    "            # minioclient.remove_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name) \n",
    "\n",
    "        # Fecha a conexão com o banco de dados PostgreSQL\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    # Em caso de erro, imprime a mensagem de erro\n",
    "    print(f\"Erro: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o Pandas e o Spark para leitura dos dados no Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Hugh Baldock Freeway, Fargo, Marion County, Oregon, 97002, United States\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'road': 'Robert Hugh Baldock Freeway',\n",
       " 'suburb': 'Fargo',\n",
       " 'county': 'Marion County',\n",
       " 'state': 'Oregon',\n",
       " 'ISO3166-2-lvl4': 'US-OR',\n",
       " 'postcode': '97002',\n",
       " 'country': 'United States',\n",
       " 'country_code': 'us'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = location.raw['address']\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "city = address.get('city', '')\n",
    "state = address.get('state', '')\n",
    "country = address.get('country', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'road': 'Robert Hugh Baldock Freeway',\n",
       " 'suburb': 'Fargo',\n",
       " 'county': 'Marion County',\n",
       " 'state': 'Oregon',\n",
       " 'ISO3166-2-lvl4': 'US-OR',\n",
       " 'postcode': '97002',\n",
       " 'country': 'United States',\n",
       " 'country_code': 'us'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cidade: Fargo\n",
      "Estado (abreviado): US-OR\n",
      "País: us\n"
     ]
    }
   ],
   "source": [
    "print(\"Cidade:\", cidade)\n",
    "print(\"Estado (abreviado):\", estado)\n",
    "print(\"País:\", pais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'gold-saint',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM tb_gpx_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552/1288466255.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas = pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_rota</th>\n",
       "      <th>nome_usuario</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>data_rota</th>\n",
       "      <th>hora_rota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10070634</td>\n",
       "      <td>HONDA_ACCORD_HYBRID_2018</td>\n",
       "      <td>45.24559097710776</td>\n",
       "      <td>-122.79781984274484</td>\n",
       "      <td>35.005</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22:06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10070634</td>\n",
       "      <td>HONDA_ACCORD_HYBRID_2018</td>\n",
       "      <td>45.24561488243122</td>\n",
       "      <td>-122.7978000436472</td>\n",
       "      <td>35.005</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22:06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10070634</td>\n",
       "      <td>HONDA_ACCORD_HYBRID_2018</td>\n",
       "      <td>45.24563834363882</td>\n",
       "      <td>-122.79778075805474</td>\n",
       "      <td>34.961</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22:06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10070634</td>\n",
       "      <td>HONDA_ACCORD_HYBRID_2018</td>\n",
       "      <td>45.24566171199957</td>\n",
       "      <td>-122.79776132359484</td>\n",
       "      <td>34.961</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22:06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10070634</td>\n",
       "      <td>HONDA_ACCORD_HYBRID_2018</td>\n",
       "      <td>45.24568465046427</td>\n",
       "      <td>-122.79774231123491</td>\n",
       "      <td>34.92</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22:06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386219</th>\n",
       "      <td>10075036</td>\n",
       "      <td>TOYOTA_COROLLA_2017</td>\n",
       "      <td>33.9952147848659</td>\n",
       "      <td>-85.98871431280011</td>\n",
       "      <td>152.481</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>03:33:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386220</th>\n",
       "      <td>10075036</td>\n",
       "      <td>TOYOTA_COROLLA_2017</td>\n",
       "      <td>33.99521479131348</td>\n",
       "      <td>-85.98871417193261</td>\n",
       "      <td>152.503</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>03:33:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386221</th>\n",
       "      <td>10075036</td>\n",
       "      <td>TOYOTA_COROLLA_2017</td>\n",
       "      <td>33.99521479225636</td>\n",
       "      <td>-85.98871401635428</td>\n",
       "      <td>152.548</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>03:33:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386222</th>\n",
       "      <td>10075036</td>\n",
       "      <td>TOYOTA_COROLLA_2017</td>\n",
       "      <td>33.99521479728368</td>\n",
       "      <td>-85.98871386889377</td>\n",
       "      <td>152.56300000000002</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>03:33:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386223</th>\n",
       "      <td>10075036</td>\n",
       "      <td>TOYOTA_COROLLA_2017</td>\n",
       "      <td>33.99521480238085</td>\n",
       "      <td>-85.9887137157907</td>\n",
       "      <td>152.601</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>03:33:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386224 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_rota              nome_usuario           latitude  \\\n",
       "0        10070634  HONDA_ACCORD_HYBRID_2018  45.24559097710776   \n",
       "1        10070634  HONDA_ACCORD_HYBRID_2018  45.24561488243122   \n",
       "2        10070634  HONDA_ACCORD_HYBRID_2018  45.24563834363882   \n",
       "3        10070634  HONDA_ACCORD_HYBRID_2018  45.24566171199957   \n",
       "4        10070634  HONDA_ACCORD_HYBRID_2018  45.24568465046427   \n",
       "...           ...                       ...                ...   \n",
       "2386219  10075036       TOYOTA_COROLLA_2017   33.9952147848659   \n",
       "2386220  10075036       TOYOTA_COROLLA_2017  33.99521479131348   \n",
       "2386221  10075036       TOYOTA_COROLLA_2017  33.99521479225636   \n",
       "2386222  10075036       TOYOTA_COROLLA_2017  33.99521479728368   \n",
       "2386223  10075036       TOYOTA_COROLLA_2017  33.99521480238085   \n",
       "\n",
       "                   longitude            elevacao   data_rota hora_rota  \n",
       "0        -122.79781984274484              35.005  2023-09-09  22:06:36  \n",
       "1         -122.7978000436472              35.005  2023-09-09  22:06:36  \n",
       "2        -122.79778075805474              34.961  2023-09-09  22:06:36  \n",
       "3        -122.79776132359484              34.961  2023-09-09  22:06:36  \n",
       "4        -122.79774231123491               34.92  2023-09-09  22:06:36  \n",
       "...                      ...                 ...         ...       ...  \n",
       "2386219   -85.98871431280011             152.481  2023-09-09  03:33:17  \n",
       "2386220   -85.98871417193261             152.503  2023-09-09  03:33:17  \n",
       "2386221   -85.98871401635428             152.548  2023-09-09  03:33:17  \n",
       "2386222   -85.98871386889377  152.56300000000002  2023-09-09  03:33:17  \n",
       "2386223    -85.9887137157907             152.601  2023-09-09  03:33:17  \n",
       "\n",
       "[2386224 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(**db_config)\n",
    "\n",
    "df_pandas = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_info_localizacao(df):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    latitudes = df['latitude'].astype(str)\n",
    "    longitudes = df['longitude'].astype(str)\n",
    "\n",
    "    def obter_localizacao(latitude, longitude):\n",
    "        location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "        address = location.raw['address']\n",
    "        cidade = address.get('suburb')\n",
    "        estado = address.get('state')\n",
    "        pais = address.get('country_code')\n",
    "        return cidade, estado, pais\n",
    "    df[['cidade', 'estado', 'pais']] = zip(*[obter_localizacao(lat, lon) for lat, lon in zip(latitudes, longitudes)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultante = obter_info_localizacao(df_pandas)\n",
    "df_resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.56.67:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>tcc-project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fab00ec6770>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos não mais usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta download para a pasta DATALAKE_STAGE\n",
    "\n",
    "# files_to_move = [files for files in os.listdir(DOWNLOADS) if files.endswith(\".gpx\")]\n",
    "# for nome_arquivos in files_to_move:\n",
    "#     origin_path = os.path.join(DOWNLOADS, nome_arquivos)\n",
    "#     destiny_path = os.path.join(DATALAKE_STAGE, nome_arquivos)\n",
    "#     os.rename(origin_path, destiny_path)\n",
    "#     print(f\"Arquivo {nome_arquivos} movido para {destiny_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta DATALAKE_STAGE para o bucket MinIO\n",
    "\n",
    "# for item in os.listdir(DATALAKE_STAGE):\n",
    "#     caminho_pre_proc = os.path.join(DATALAKE_STAGE, item)\n",
    "#     print(caminho_pre_proc)\n",
    "# \n",
    "#     if os.path.isfile(caminho_pre_proc):\n",
    "#         try:\n",
    "#             minioclient.fput_object(DATA_LAKE, item, caminho_pre_proc)\n",
    "#             print(f\"Arquivo {item} enviado com sucesso para o bucket.\")\n",
    "#         except S3Error as err:\n",
    "#             print(f\"Erro ao enviar o arquivo {item}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DADOS PARA INSERIR NA TABELA DE CONTROLE USANDO O BEAUTIFULSOAP ## #\n",
    "# navegador = requests.get('https://www.openstreetmap.org/user/sunnypilot/traces/9255974')\n",
    "# site = BeautifulSoup(navegador.text, 'html.parser')\n",
    "# data_trace = site.find('div', attrs={'class': 'content-body'})\n",
    "# table_trace = data_trace.find('table')\n",
    "# \n",
    "# filename_row = table_trace.find('th', string='Filename:').parent\n",
    "# owner_row = table_trace.find('th', string='Owner:').parent\n",
    "# uploaded_row = table_trace.find('th', string='Uploaded:').parent\n",
    "# \n",
    "# filename = filename_row.find('td').text.strip().replace('(download)','').strip()\n",
    "# owner = owner_row.find('td').text.strip()\n",
    "# uploaded = uploaded_row.find('td').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ESTE TRECHO TEM A FINALIDADE DE BAIXAR OS ARQUIVOS ## #\n",
    "#list_rotas_finalizadas\n",
    "#list_rotas_pendentes\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td - finalizado\n",
    "# //*[@id=\"content\"]/div[2]/div/span = PENDENTE\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td - pendente\n",
    "\n",
    "# ## Trecho descontinuado -- Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "# navegador = webdriver.Chrome(service=servico)\n",
    "# for list_route in lista_rotas:\n",
    "#     sleep(3)\n",
    "#     url = list_route[0]\n",
    "#     navegador.get(url)  #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "#     navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "# navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n",
    "# Coalesce o DataFrame para um único arquivo\n",
    "df_single_file = df.coalesce(1)\n",
    "# Salve o DataFrame coalesced como um único arquivo CSV\n",
    "df_single_file.write.csv(csv_caminho_arquivo, header=True, mode=\"overwrite\")\n",
    "Dessa forma o spark gera um csv particionado\n",
    "df.write.csv('pyspark_dataframe.csv', header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
