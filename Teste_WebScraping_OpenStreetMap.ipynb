{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias para a raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando o site Open Street Map e capturando as rotas pendentes e as rotas finalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_rotas_pendentes = []\n",
    "list_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # list_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # list_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a telas para efetuar os downloads - Renomeando os arquivo adicionando o nome dos usuários - Movendo para a pasta PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_conteudo_da_pagina = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_conteudo_da_pagina, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "time.sleep(3)\n",
    "navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        novo_nome = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for user, arquivo_para_renomear_gpx in zip(users, arquivos_para_renomear_gpx):\n",
    "    if os.listdir(DOWNLOADS):\n",
    "        caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)        \n",
    "        novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "        caminho_novo = os.path.join(DOWNLOADS,novo_nome)        \n",
    "        #print(caminho_novo)\n",
    "        os.rename(caminho_antigo, caminho_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSING, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1ª Função. Responsável por fazer o download das rotas diretamente site, renomear os arquivos e os mover para a pasta de pré processamento - Essa execução deve ser executada de uma única vez, pois pode haver alguma falha no momento de renomear os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIXO_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "rotas = site.findAll('tr')\n",
    "\n",
    "lista_rotas_pendentes = []\n",
    "lista_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for rota in rotas:\n",
    "    if rota.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = rota.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # lista_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # lista_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "\n",
    "## Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "#navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "\n",
    "## Baixando os arquivos \n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "usuarios = []\n",
    "for lista_rota in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = lista_rota[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    conteudo_pagina_download = navegador.page_source\n",
    "    pagina_usuario = BeautifulSoup(conteudo_pagina_download, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in pagina_usuario):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "time.sleep(5)\n",
    "navegador.close()\n",
    "\n",
    "\n",
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "arquivos_para_renomear = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for arquivo_para_renomear in arquivos_para_renomear:\n",
    "        novo_nome = arquivo_para_renomear.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, arquivo_para_renomear), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for usuario, arquivo_para_renomear_gpx in zip(usuarios, arquivos_para_renomear_gpx):        \n",
    "    caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)\n",
    "    novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{usuario}.gpx\"        \n",
    "    caminho_novo = os.path.join(DOWNLOADS,novo_nome)            \n",
    "    os.rename(caminho_antigo, caminho_novo)\n",
    "\n",
    "\n",
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSAMENTO, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSAMENTO}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ª Função - Lendo arquivos pasta de Pré Processamento - Convertendo os arquivos .gpx em .csv - Levando os arquivos .csv para a camada bronze do datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "### IMPORTAÇÃO DAS BIBLIOTECAS NECESSÁRIAS ###\n",
    "##############################################\n",
    "# pip install minio \n",
    "# pip install gpxpy\n",
    "# pip install pandas \n",
    "\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd \n",
    "import os \n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "##############################\n",
    "### DEFINIÇÃO DE VARIÁVEIS ### \n",
    "##############################\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO' \n",
    "CAMADA_BRONZE = 'bronze' \n",
    "\n",
    "##############################################\n",
    "### CRIANDO UMA INSTÂNCIA DO CLIENTE MINIO ###\n",
    "##############################################\n",
    "minioclient = Minio('localhost:9000', \n",
    "    access_key='minioadmin', \n",
    "    secret_key='minioadmin', \n",
    "    secure=False) \n",
    "\n",
    "###########################################################\n",
    "### CONVERTENDO OS ARQUIVOS COM A EXTENSÃO .GPX EM .CSV ###\n",
    "###########################################################\n",
    "arquivos_pre_processamento = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".gpx\")] \n",
    "for arquivo_pre_processamento in arquivos_pre_processamento: \n",
    "    caminho_arquivo = os.path.join(PRE_PROCESSAMENTO, arquivo_pre_processamento) \n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo_gpx: \n",
    "            gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "        info_rota = [] \n",
    "        for trilha in gpx.tracks: \n",
    "            for segmento in trilha.segments:\n",
    "                for ponto in segmento.points:\n",
    "                    info_rota.append({\n",
    "                        'latitude': ponto.latitude, \n",
    "                        'longitude': ponto.longitude, \n",
    "                        'elevacao' : ponto.elevation, \n",
    "                        'time_point' : ponto.time \n",
    "                    })\n",
    "        arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv') \n",
    "        info_rota_df = pd.DataFrame(info_rota) \n",
    "        info_rota_df.to_csv(f'{PRE_PROCESSAMENTO}/{arquivo_pre_processamento_csv}', index=False) \n",
    "        os.remove(caminho_arquivo) \n",
    "    except Exception as e: \n",
    "        print(f\"Erro ao converter o '{arquivo_pre_processamento}': {e}.\") \n",
    "        os.remove(caminho_arquivo)\n",
    "        print(f\"Excluindo o arquivo defeituoso: {arquivo_pre_processamento}\")\n",
    "        \n",
    "\n",
    "################################################################################################################\n",
    "### MOVENDO OS ARQUIVOS COM A EXTENSÃO .CSV DA PASTA PRE_PROCESSAMENTO PARA A PRIMEIRA CAMADA (BRONZE) NO MINIO ###\n",
    "################################################################################################################\n",
    "arquivos_para_datalake = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".csv\")] \n",
    "for nome_arquivo in arquivos_para_datalake: \n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSAMENTO, nome_arquivo) \n",
    "    if os.path.isfile(caminho_pre_proc): \n",
    "        try:\n",
    "            minioclient.fput_object(CAMADA_BRONZE, nome_arquivo, caminho_pre_proc) \n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\") \n",
    "            os.remove(caminho_pre_proc) \n",
    "        except S3Error as e: \n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO/10086735__Routes_from_dragonpilot_2023_08_15__TOYOTA_RAV4_HYBRID_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "for trilha in gpx.tracks:\n",
    "    for segmento in trilha.segments:\n",
    "        for ponto in segmento.points:            \n",
    "            \n",
    "            latitude = ponto.latitude\n",
    "            longitude = ponto.longitude\n",
    "\n",
    "            address = location.raw['address']\n",
    "            city = address.get('city', '')\n",
    "            state = address.get('state', '')\n",
    "            country = address.get('country', '')\n",
    "\n",
    "            location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "            address = location.raw['address']\n",
    "            cidade = address.get('suburb')\n",
    "            estado = address.get('state')\n",
    "            pais = address.get('country_code')\n",
    "\n",
    "            info_rota.append({\n",
    "                'latitude': ponto.latitude,\n",
    "                'longitude': ponto.longitude,\n",
    "                'elevacao' : ponto.elevation,\n",
    "                'time_point' : ponto.time,\n",
    "                'cidade': cidade,\n",
    "                'estado': estado,\n",
    "                'pais': pais\n",
    "            })\n",
    "arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv')\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "## os.remove(caminho_arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')\n",
    "\n",
    "estado = estado[-2:]\n",
    "pais = pais.upper()\n",
    "\n",
    "print(f\"Cidade: {cidade}\")\n",
    "print(f\"Estado (abreviado): {estado[-2:]}\")\n",
    "print(f\"País: {pais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADRAO_REGEX = r'(.*?)__'\n",
    "padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "id_rota = padrao_encontrado[0]\n",
    "nome_usuario = padrao_encontrado[-1]\n",
    "padrao_encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")]\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".parquet\")]\n",
    "len(arquivos_para_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos com a extensão .csv saem da pasta PRE_PROCESSING para a primeira camada (bronze) no MinIO\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "for nome_arquivo in arquivos_para_datalake:\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSING, nome_arquivo)    \n",
    "    if os.path.isfile(caminho_pre_proc):\n",
    "        try:\n",
    "            minioclient.fput_object(BRONZE_LAYER, nome_arquivo, caminho_pre_proc)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\")\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta download\n",
    "        except S3Error as e:\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRE_PROCESSING/9632214__Routes_from_sunnypilot_2023_08_19-dev__SUBARU_IMPREZA_LIMITED_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = '9632229__Routes_from_sunnypilot_2023_08_19-dev__HYUNDAI_SANTA_FE_2019__.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = str(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo_gpx, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a quantidade de pontos (lat+lon+ele) em um arquivo arquivo '.gpx' podemos usar get\n",
    "# Documentação: https://pypi.org/project/gpxpy/\n",
    "gpx.get_track_points_no()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a faixa de altitude, a fim de se obter extremos de maior elevação e menor elevação no trajeto percorrido - os valores apresentados são em metros acima do nível do mar\n",
    "gpx.get_elevation_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não endendi para que isso serve\n",
    "gpx.get_uphill_downhill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o nome do criador da rota - Entretanto no nosso caso quando usamos esse comando temos uma informação generica - Foi necessário obter o nome do criador da rota com o WebScraping\n",
    "creator = gpx.creator\n",
    "creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exibir o conteudo do arquivo .gpx em formato xml\n",
    "print(gpx.to_xml()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possivel verificar quantas rotas/trilhas nosso arquivo .gpx possui\n",
    "len(gpx.tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no nosso exemplo acima só temos 1 rota/trilha efetuada, podemos acessar por meio de indice no python, \n",
    "# Nesse caso se passa o valor [0] para ter uma precisão exata da rota em que estamos trabalhando\n",
    "gpx.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos acessar os segmentos da nossa rota/trilha\n",
    "gpx.tracks[0].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos acessar os pontos de dados individuais dentro do nosso gpx acessando a matriz de pontos. Aqui tambem podemo0s ver o nome das propriedades do arquivo como elevation e time\n",
    "gpx.tracks[0].segments[0].points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui acessamos as tres camadas: Track - Segments e Point e o passamos para um array em forma de dicionário. Note que podemos acessar cada atributo. No meu caso estou pegando latitude, Longitude, Elevação e a hora de cada ponto (entenda-se como ponto Lat+Long+Ele)\n",
    "info_rota = []\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            info_rota.append({\n",
    "                'latitude': point.latitude,\n",
    "                'longitude': point.longitude,\n",
    "                'elevacao' : point.elevation,\n",
    "                'time_point' : point.time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo somente os 3 primeiros resultados\n",
    "info_rota[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui podemos transformar essa informação em um dataframe com a biblioteca pandas\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_csv('pandas_info_rota.csv', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_parquet('pd_parquet_info_rota.parquet', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3ª Função - Lendo o bucket e transformando os arquivos encontrados lá em DF Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "CAMADA_SILVER = 'silver'\n",
    "PADRAO_REGEX = r'(.*?)__'\n",
    "\n",
    "PADRAO_REGEX_1 = r'(\\d+)__(.*?)\\.csv'\n",
    "PADRAO_REGEX_2 = r'(.*?)__'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<minio.datatypes.Object at 0x7f2dd0b5b1f0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "    try:\n",
    "\n",
    "        ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "        obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "        csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "        arquivo_csv = StringIO(csv_decod)\n",
    "        df = pd.read_csv(arquivo_csv, sep=';')\n",
    "\n",
    "        #### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "        df['time_point'] = pd.to_datetime(df['time_point'], format='%Y-%m-%d %H:%M:%S', errors='coerce')        \n",
    "\n",
    "        df['data'] = df['time_point'].dt.date\n",
    "        df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "               \n",
    "        \n",
    "        df = df.drop(columns=['time_point'])\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao alterar a data do arquivo: {nome_arquivo}. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "\n",
    "    ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv, sep=';')\n",
    "\n",
    "    ### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "    df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "    df['data'] = df['time_point'].dt.date\n",
    "    df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "    df = df.drop(columns=['time_point']) \n",
    "\n",
    "    ### USANDO O REGEX PARA PEGAR O ID DA RODA E O NOME DO USUÁRIO (DADOS PRESENTES NO NOME DO ARQUIVO) ###\n",
    "    nome_arquivo = arquivo_rotas_gpx_csv.object_name        \n",
    "    padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "    id_rota = padrao_encontrado[0]\n",
    "    nome_usuario = padrao_encontrado[-1]\n",
    "    num_df = len(df)\n",
    "    replic_id_rota = np.tile(id_rota, num_df)\n",
    "    replic_nome_usuario = np.tile(nome_usuario, num_df)\n",
    "    df['id_rota'] = replic_id_rota\n",
    "    df['nome_usuario'] = replic_nome_usuario\n",
    "    ordenacao_df = ['id_rota', 'nome_usuario', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "    df = df.reindex(columns=ordenacao_df)\n",
    "\n",
    "    try:\n",
    "        csv_bytes = df.to_csv(index=False).encode('utf-8') \n",
    "        csv_buffer = BytesIO(csv_bytes)\n",
    "        minioclient.put_object(\n",
    "                            CAMADA_SILVER,\n",
    "                            nome_arquivo,\n",
    "                            data=csv_buffer,\n",
    "                            length=len(csv_bytes),\n",
    "                            content_type='application/csv')\n",
    "\n",
    "        #minioclient.remove_object(CAMADA_BRONZE, nome_arquivo)        \n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao enviar o arquivo: {nome_arquivo} para a [camada silver]. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADRAO_REGEX_1 = r'(\\d+)__(.*?)\\.csv'\n",
    "PADRAO_REGEX_2 = r'(.*?)__'\n",
    "\n",
    "for nome_arquivo in strings:\n",
    "    padrao_encontrado = re.search(PADRAO_REGEX_1, nome_arquivo)\n",
    "    if padrao_encontrado:\n",
    "        id_rota = padrao_encontrado.group(1)\n",
    "        nome_usuario = padrao_encontrado.group(2)\n",
    "\n",
    "        substrings = re.findall(PADRAO_REGEX_2, nome_usuario)\n",
    "        if substrings:\n",
    "            nome_usuario = substrings[-1]\n",
    "        else:\n",
    "            nome_usuario = nome_usuario\n",
    "       \n",
    "        print(f\"ID da Rota: {id_rota}\")\n",
    "        print(f\"Nome do Usuário: {nome_usuario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_rota_csv = minioclient.get_object(BRONZE_LAYER, '9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv')\n",
    "rota_csv = blob_rota_csv.data\n",
    "rota_csv = rota_csv.decode(\"ISO-8859-1\")\n",
    "pre_df = StringIO(rota_csv)\n",
    "df = pd.read_csv(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text = \"9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx\"\n",
    "\n",
    "# Definindo o padrão de regex\n",
    "pattern = r'(.*?)__'\n",
    "\n",
    "# Encontrando todas as correspondências no texto\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Extraindo o nome do carro\n",
    "username = matches[-1]\n",
    "id = matches[0]\n",
    "\n",
    "print(f'Id: {id} - username: {username}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = repeated_id\n",
    "df['username'] = repeated_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Suas strings de exemplo\n",
    "strings = [\n",
    "    \"10109849__Muara_Bulian.csv\",\n",
    "    \"10109852__Routes_from_sunnypilot_0_9_4_1-release__VOLKSWAGEN_PASSAT_8TH_GEN__.csv\",\n",
    "    \"10127398__Jambi_Paradise_-_Simpang_Paal_Merah.csv\"\n",
    "]\n",
    "\n",
    "# Padrão regex\n",
    "PADRAO_REGEX_1 = r'(\\d+)__(.*?)\\.csv'\n",
    "PADRAO_REGEX_2 = r'(.*?)__'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome_arquivo in strings:\n",
    "    padrao_encontrado = re.search(PADRAO_REGEX_1, nome_arquivo)\n",
    "    if padrao_encontrado:\n",
    "        id_rota = padrao_encontrado.group(1)\n",
    "        nome_usuario = padrao_encontrado.group(2)\n",
    "\n",
    "        substrings = re.findall(PADRAO_REGEX_2, nome_usuario)\n",
    "        if substrings:\n",
    "            nome_usuario = substrings[-1]\n",
    "        else:\n",
    "            nome_usuario = nome_usuario\n",
    "       \n",
    "        print(f\"ID da Rota: {id_rota}\")\n",
    "        print(f\"Nome do Usuário: {nome_usuario}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Suas strings de exemplo\n",
    "strings = [\n",
    "    \"10109849__Muara_Bulian.csv\",\n",
    "    \"10109852__Routes_from_sunnypilot_0_9_4_1-release__VOLKSWAGEN_PASSAT_8TH_GEN__.csv\",\n",
    "    \"10127398__Jambi_Paradise_-_Simpang_Paal_Merah.csv\"\n",
    "]\n",
    "\n",
    "# Padrão regex\n",
    "PADRAO_REGEX_1 = r'(\\d+)__(.*?)\\.csv'\n",
    "PADRAO_REGEX_2 = r'(.*?)__'\n",
    "\n",
    "for nome_arquivo in strings:\n",
    "    padrao_encontrado = re.search(PADRAO_REGEX_1, nome_arquivo)\n",
    "    if padrao_encontrado:\n",
    "        id_rota = padrao_encontrado.group(1)\n",
    "        nome_usuario = padrao_encontrado.group(2)\n",
    "\n",
    "        substrings = re.findall(PADRAO_REGEX_2, nome_usuario)\n",
    "        if substrings:\n",
    "            nome_usuario = substrings[-1]\n",
    "        else:\n",
    "            nome_usuario = nome_usuario\n",
    "       \n",
    "        print(f\"ID da Rota: {id_rota}\")\n",
    "        print(f\"Nome do Usuário: {nome_usuario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ª Função - Lendo o bucket Silver e Escrevendo os arquivos no banco de dados Postgres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2\n",
    "import psycopg2\n",
    "import os\n",
    "from minio import Minio\n",
    "import io\n",
    "\n",
    "CAMADA_SILVER = 'silver'\n",
    "\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "\n",
    "db_config = {\n",
    "'host': 'localhost',\n",
    "'database': 'gold-saint',\n",
    "'user': 'postgres',\n",
    "'password': 'postgres',\n",
    "}\n",
    "\n",
    "copy_sql = \"\"\"\n",
    "    COPY tb_gpx_full (id_rota, nome_usuario, latitude, longitude, elevacao, data_rota, hora_rota)\n",
    "    FROM stdin WITH CSV HEADER DELIMITER as ','\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "if not arquivos_rotas_gpx_csv:\n",
    "    print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "else:\n",
    "    print(f\"Existem {len(arquivos_rotas_gpx_csv)} arquivos no Bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Lista todos os arquivos na camada \"silver\" do Minio que têm extensão .csv\n",
    "    arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "    \n",
    "    # Verifica se há arquivos no bucket antes de continuar\n",
    "    if not arquivos_rotas_gpx_csv:\n",
    "        print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "\n",
    "    else:\n",
    "        # Conexão com o banco de dados PostgreSQL\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Itera sobre cada arquivo CSV encontrado no Minio\n",
    "        for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "            # Obtém o objeto do arquivo CSV do Minio  \n",
    "            obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)            \n",
    "\n",
    "            # Decodifica os dados do arquivo CSV de bytes para string\n",
    "            csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string            \n",
    "\n",
    "            # Usa io.StringIO para criar um objeto de arquivo legível a partir da string CSV\n",
    "            with io.StringIO(csv_decod) as file:        \n",
    "\n",
    "                # Executa o comando COPY para inserir os dados no banco de dados PostgreSQL\n",
    "                cursor.copy_expert(sql=copy_sql, file=file)\n",
    "\n",
    "            # Commit para salvar as alterações no banco de dados    \n",
    "            conn.commit()        \n",
    "\n",
    "            # Remove o arquivo do bucket \"silver\" no Minio após ser processado\n",
    "            # minioclient.remove_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name) \n",
    "\n",
    "        # Fecha a conexão com o banco de dados PostgreSQL\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    # Em caso de erro, imprime a mensagem de erro\n",
    "    print(f\"Erro: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5ª Função - Enriquecendo o DF com informação de pais - estado e cidade - Carregando o DF Enriquecido na camada GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "CAMADA_SILVER = 'silver'\n",
    "CAMADA_GOLD = 'gold'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_locations_equal(location1, location2):\n",
    "    return location1 == location2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:    \n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:    \n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv, sep=';')\n",
    "\n",
    "    batch_size = 1000\n",
    "    batch_list = [df[i:i+batch_size].copy() for i in range(0, len(df), batch_size)]\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\", timeout=10)\n",
    "    processed_batches = []  # Inicialize a lista de lotes processados\n",
    "    last_locations = {}\n",
    "\n",
    "    for batch_df in batch_list:\n",
    "        # Obtenha a primeira e a última linha do lote\n",
    "        first_row = batch_df.iloc[0]\n",
    "        last_row = batch_df.iloc[-1]\n",
    "\n",
    "        first_location_str = f\"{first_row['latitude']},{first_row['longitude']}\"\n",
    "        last_location_str = f\"{last_row['latitude']},{last_row['longitude']}\"\n",
    "\n",
    "        # Verifique se a primeira e a última localização são iguais à última localização verificada\n",
    "        if are_locations_equal(first_location_str, last_location_str) and are_locations_equal(first_location_str, last_location):\n",
    "            # Se forem iguais, não é necessário consultar o serviço novamente\n",
    "            location = last_location\n",
    "        else:\n",
    "            # Se forem diferentes, consulte o serviço de geocodificação para a última localização\n",
    "            location = geolocator.reverse(last_location_str)\n",
    "            last_location = location\n",
    "\n",
    "        address = location.raw['address']\n",
    "        cidade = address.get('county') or address.get('city') or address.get('suburb')\n",
    "        estado = address.get('ISO3166-2-lvl4').split('-')[1]\n",
    "        pais = address.get('country_code')\n",
    "                \n",
    "        pais = pais.upper()\n",
    "        \n",
    "        df.loc[:, 'cidade'] = cidade\n",
    "        df.loc[:, 'estado'] = estado\n",
    "        df.loc[:, 'pais'] = pais\n",
    "\n",
    "    # Converta o DataFrame enriquecido de volta para CSV\n",
    "    enriched_csv = df.to_csv(index=False, sep=';')\n",
    "    enriched_csv_bytes = enriched_csv.encode('utf-8')\n",
    "\n",
    "    # Crie um buffer de bytes\n",
    "    enriched_csv_buffer = BytesIO(enriched_csv_bytes)\n",
    "\n",
    "    minioclient.put_object(\n",
    "        CAMADA_GOLD,\n",
    "        arquivo_rotas_gpx_csv.object_name,  # Use o mesmo nome de arquivo\n",
    "        data=enriched_csv_buffer,\n",
    "        length=len(enriched_csv_bytes),\n",
    "        content_type='application/csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'result' seja o dicionário retornado pela geocodificação\n",
    "address = result.raw['address']\n",
    "\n",
    "cidade = None\n",
    "estado = None\n",
    "pais = None\n",
    "\n",
    "# Mapeie os atributos de endereço para os nomes padronizados\n",
    "for key, aliases in address_mappings.items():\n",
    "    for alias in aliases:\n",
    "        if alias in address:\n",
    "            if key == 'city' or key == 'county':\n",
    "                cidade = address[alias]                            \n",
    "            \n",
    "\n",
    "# Agora você tem 'cidade', 'estado' e 'pais' padronizados independentemente do formato de endereço\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:    \n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO/10125901__Routes_from_sunnypilot_0_9_4_1-release__KIA_EV6_2022__.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"40.82486026618991\"\n",
    "Longitude = \"-87.99828066563114\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'road': 'I 57',\n",
       " 'county': 'Iroquois County',\n",
       " 'state': 'Illinois',\n",
       " 'ISO3166-2-lvl4': 'US-IL',\n",
       " 'postcode': '60930',\n",
       " 'country': 'United States',\n",
       " 'country_code': 'us'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = location.raw['address']\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidade = address.get('county') or address.get('city') or address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4').split('-')[1]\n",
    "pais = address.get('country_code')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')\n",
    "\n",
    "estado = estado[-2:]\n",
    "pais = pais.upper()\n",
    "\n",
    "print(f\"Cidade: {cidade}\")\n",
    "print(f\"Estado (abreviado): {estado[-2:]}\")\n",
    "print(f\"País: {pais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "cidade = address.get('county')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o Pandas e o Spark para leitura dos dados no Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "city = address.get('city', '')\n",
    "state = address.get('state', '')\n",
    "country = address.get('country', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Hugh Baldock Freeway, Fargo, Marion County, Oregon, 97002, United States\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'road': 'Robert Hugh Baldock Freeway',\n",
       " 'suburb': 'Fargo',\n",
       " 'county': 'Marion County',\n",
       " 'state': 'Oregon',\n",
       " 'ISO3166-2-lvl4': 'US-OR',\n",
       " 'postcode': '97002',\n",
       " 'country': 'United States',\n",
       " 'country_code': 'us'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cidade:\", cidade)\n",
    "print(\"Estado (abreviado):\", estado)\n",
    "print(\"País:\", pais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'gold-saint',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM tb_gpx_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_config)\n",
    "\n",
    "df_pandas = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_info_localizacao(df):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    latitudes = df['latitude'].astype(str)\n",
    "    longitudes = df['longitude'].astype(str)\n",
    "\n",
    "    def obter_localizacao(latitude, longitude):\n",
    "        location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "        address = location.raw['address']\n",
    "        cidade = address.get('suburb')\n",
    "        estado = address.get('state')\n",
    "        pais = address.get('country_code')\n",
    "        return cidade, estado, pais\n",
    "    df[['cidade', 'estado', 'pais']] = zip(*[obter_localizacao(lat, lon) for lat, lon in zip(latitudes, longitudes)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultante = obter_info_localizacao(df_pandas)\n",
    "df_resultante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API para criar tabela com preco de combustível -- API para cirar um DF com o consumo de cada veículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para o combustivel - fazer um webscraping da tabela da anp\n",
    "# https://www.gov.br/anp/pt-br/assuntos/precos-e-defesa-da-concorrencia/precos/precos-de-distribuicao-de-combustiveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "db_config = {\n",
    "'host': 'localhost',\n",
    "'database': 'gold-saint',\n",
    "'user': 'postgres',\n",
    "'password': 'postgres',\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "consulta_usuarios_gpx_full = \"\"\"\n",
    "select distinct\n",
    "split_part(LOWER(nome_usuario),'_',1) as marca,\n",
    "split_part(LOWER(nome_usuario),'_',2) as modelo\n",
    "from tb_gpx_full\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(consulta_usuarios_gpx_full)\n",
    "resultados_usuarios_gpx_full = cursor.fetchall()\n",
    "df_usuarios_full = pd.DataFrame(resultados_usuarios_gpx_full, columns=[desc[0] for desc in cursor.description])\n",
    "df_usuarios_full.head()\n",
    "\n",
    "df_marcas = df_usuarios_full['marca'].tolist()\n",
    "df_modelos = df_usuarios_full['modelo'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marca = 'ram'\n",
    "df_modelo = '1500'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "make = df_marca\n",
    "model = df_modelo\n",
    "api_url = 'https://api.api-ninjas.com/v1/cars?model={}'.format(make,model)\n",
    "response = requests.get(api_url, headers={'X-Api-Key': '/DHg+PPb3h7gYITeEup54w==KXt6OHpmw3zMNgfE'})\n",
    "if response.status_code == requests.codes.ok:    \n",
    "    df = pd.DataFrame(response.text)\n",
    "\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "make = df_marca  # Substitua df_marca pelo valor desejado\n",
    "model = df_modelo  # Substitua df_modelo pelo valor desejado\n",
    "api_url = 'https://api.api-ninjas.com/v1/cars?model={}'.format(make,model)\n",
    "headers = {'X-Api-Key': '/DHg+PPb3h7gYITeEup54w==KXt6OHpmw3zMNgfE'}\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Converte o JSON da resposta em um objeto Python\n",
    "        df = pd.DataFrame(data)  # Cria um DataFrame com base nos dados\n",
    "        print(df)\n",
    "    else:\n",
    "        print(\"Erro:\", response.status_code, response.text)\n",
    "except Exception as e:\n",
    "    print(\"Erro ao fazer a solicitação à API:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>class</th>\n",
       "      <th>combination_mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>transmission</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>small pickup truck</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>21</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ram 50 pickup 2wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>small pickup truck</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>22</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ram 50 pickup 2wd</td>\n",
       "      <td>m</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>standard pickup truck</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>awd</td>\n",
       "      <td>gas</td>\n",
       "      <td>19</td>\n",
       "      <td>dodge</td>\n",
       "      <td>power ram 50 4wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>standard pickup truck</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>awd</td>\n",
       "      <td>gas</td>\n",
       "      <td>20</td>\n",
       "      <td>dodge</td>\n",
       "      <td>power ram 50 4wd</td>\n",
       "      <td>m</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>special purpose vehicle</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>12</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ad100/ad150 ramcharger 2wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_mpg                    class  combination_mpg  cylinders  \\\n",
       "0        17       small pickup truck               19          4   \n",
       "1        17       small pickup truck               19          4   \n",
       "2        16    standard pickup truck               17          4   \n",
       "3        17    standard pickup truck               18          4   \n",
       "4        11  special purpose vehicle               11          8   \n",
       "\n",
       "   displacement drive fuel_type  highway_mpg   make  \\\n",
       "0           2.4   rwd       gas           21  dodge   \n",
       "1           2.4   rwd       gas           22  dodge   \n",
       "2           2.4   awd       gas           19  dodge   \n",
       "3           2.4   awd       gas           20  dodge   \n",
       "4           5.2   rwd       gas           12  dodge   \n",
       "\n",
       "                        model transmission  year  \n",
       "0           ram 50 pickup 2wd            a  1993  \n",
       "1           ram 50 pickup 2wd            m  1993  \n",
       "2            power ram 50 4wd            a  1993  \n",
       "3            power ram 50 4wd            m  1993  \n",
       "4  ad100/ad150 ramcharger 2wd            a  1985  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convertendo milha para Km - (1 milha equivale a aproximadamente 1,60934 km)\n",
    "km_cidade = df['city_mpg'] * 1.60934\n",
    "km_estrada = df['highway_mpg'] * 1.60934\n",
    "\n",
    "## Convertendo galao para litro - (1 galão equivale a aproximadamente 3,78541 litros)\n",
    "litro_cidade = df['city_mpg'] * 3.78541\n",
    "litro_estrada = df['highway_mpg'] * 3.78541\n",
    "\n",
    "km_cidade =  km_cidade.mean()\n",
    "km_estrada =  km_estrada.mean()\n",
    "litro_cidade = litro_cidade.mean()\n",
    "litro_estrada = litro_estrada.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3521505710415456"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = litro_cidade / km_cidade\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o consumo em litros por quilômetro (L/km)\n",
    "df['consumo_litros_por_km_cidade'] = litro_cidade / km_cidade\n",
    "df['consumo_litros_por_km_estrada'] = litro_estrada / km_estrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o consumo em km/L\n",
    "df['consumo_km_por_litro_cidade'] = km_cidade / litro_cidade\n",
    "df['consumo_km_por_litro_estrada'] = km_estrada / litro_estrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>class</th>\n",
       "      <th>combination_mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>transmission</th>\n",
       "      <th>year</th>\n",
       "      <th>consumo_km_por_litro_cidade</th>\n",
       "      <th>consumo_km_por_litro_estrada</th>\n",
       "      <th>consumo_litros_por_km_cidade</th>\n",
       "      <th>consumo_litros_por_km_estrada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>small pickup truck</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>21</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ram 50 pickup 2wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>2.352151</td>\n",
       "      <td>2.352151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>small pickup truck</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>22</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ram 50 pickup 2wd</td>\n",
       "      <td>m</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>2.352151</td>\n",
       "      <td>2.352151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>standard pickup truck</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>awd</td>\n",
       "      <td>gas</td>\n",
       "      <td>19</td>\n",
       "      <td>dodge</td>\n",
       "      <td>power ram 50 4wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>2.352151</td>\n",
       "      <td>2.352151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>standard pickup truck</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>awd</td>\n",
       "      <td>gas</td>\n",
       "      <td>20</td>\n",
       "      <td>dodge</td>\n",
       "      <td>power ram 50 4wd</td>\n",
       "      <td>m</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>2.352151</td>\n",
       "      <td>2.352151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>special purpose vehicle</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>rwd</td>\n",
       "      <td>gas</td>\n",
       "      <td>12</td>\n",
       "      <td>dodge</td>\n",
       "      <td>ad100/ad150 ramcharger 2wd</td>\n",
       "      <td>a</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>2.352151</td>\n",
       "      <td>2.352151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_mpg                    class  combination_mpg  cylinders  \\\n",
       "0        17       small pickup truck               19          4   \n",
       "1        17       small pickup truck               19          4   \n",
       "2        16    standard pickup truck               17          4   \n",
       "3        17    standard pickup truck               18          4   \n",
       "4        11  special purpose vehicle               11          8   \n",
       "\n",
       "   displacement drive fuel_type  highway_mpg   make  \\\n",
       "0           2.4   rwd       gas           21  dodge   \n",
       "1           2.4   rwd       gas           22  dodge   \n",
       "2           2.4   awd       gas           19  dodge   \n",
       "3           2.4   awd       gas           20  dodge   \n",
       "4           5.2   rwd       gas           12  dodge   \n",
       "\n",
       "                        model transmission  year  consumo_km_por_litro_cidade  \\\n",
       "0           ram 50 pickup 2wd            a  1993                     0.425143   \n",
       "1           ram 50 pickup 2wd            m  1993                     0.425143   \n",
       "2            power ram 50 4wd            a  1993                     0.425143   \n",
       "3            power ram 50 4wd            m  1993                     0.425143   \n",
       "4  ad100/ad150 ramcharger 2wd            a  1985                     0.425143   \n",
       "\n",
       "   consumo_km_por_litro_estrada  consumo_litros_por_km_cidade  \\\n",
       "0                      0.425143                      2.352151   \n",
       "1                      0.425143                      2.352151   \n",
       "2                      0.425143                      2.352151   \n",
       "3                      0.425143                      2.352151   \n",
       "4                      0.425143                      2.352151   \n",
       "\n",
       "   consumo_litros_por_km_estrada  \n",
       "0                       2.352151  \n",
       "1                       2.352151  \n",
       "2                       2.352151  \n",
       "3                       2.352151  \n",
       "4                       2.352151  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos não mais usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta download para a pasta DATALAKE_STAGE\n",
    "\n",
    "# files_to_move = [files for files in os.listdir(DOWNLOADS) if files.endswith(\".gpx\")]\n",
    "# for nome_arquivos in files_to_move:\n",
    "#     origin_path = os.path.join(DOWNLOADS, nome_arquivos)\n",
    "#     destiny_path = os.path.join(DATALAKE_STAGE, nome_arquivos)\n",
    "#     os.rename(origin_path, destiny_path)\n",
    "#     print(f\"Arquivo {nome_arquivos} movido para {destiny_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta DATALAKE_STAGE para o bucket MinIO\n",
    "\n",
    "# for item in os.listdir(DATALAKE_STAGE):\n",
    "#     caminho_pre_proc = os.path.join(DATALAKE_STAGE, item)\n",
    "#     print(caminho_pre_proc)\n",
    "# \n",
    "#     if os.path.isfile(caminho_pre_proc):\n",
    "#         try:\n",
    "#             minioclient.fput_object(DATA_LAKE, item, caminho_pre_proc)\n",
    "#             print(f\"Arquivo {item} enviado com sucesso para o bucket.\")\n",
    "#         except S3Error as err:\n",
    "#             print(f\"Erro ao enviar o arquivo {item}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DADOS PARA INSERIR NA TABELA DE CONTROLE USANDO O BEAUTIFULSOAP ## #\n",
    "# navegador = requests.get('https://www.openstreetmap.org/user/sunnypilot/traces/9255974')\n",
    "# site = BeautifulSoup(navegador.text, 'html.parser')\n",
    "# data_trace = site.find('div', attrs={'class': 'content-body'})\n",
    "# table_trace = data_trace.find('table')\n",
    "# \n",
    "# filename_row = table_trace.find('th', string='Filename:').parent\n",
    "# owner_row = table_trace.find('th', string='Owner:').parent\n",
    "# uploaded_row = table_trace.find('th', string='Uploaded:').parent\n",
    "# \n",
    "# filename = filename_row.find('td').text.strip().replace('(download)','').strip()\n",
    "# owner = owner_row.find('td').text.strip()\n",
    "# uploaded = uploaded_row.find('td').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ESTE TRECHO TEM A FINALIDADE DE BAIXAR OS ARQUIVOS ## #\n",
    "#list_rotas_finalizadas\n",
    "#list_rotas_pendentes\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td - finalizado\n",
    "# //*[@id=\"content\"]/div[2]/div/span = PENDENTE\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td - pendente\n",
    "\n",
    "# ## Trecho descontinuado -- Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "# navegador = webdriver.Chrome(service=servico)\n",
    "# for list_route in lista_rotas:\n",
    "#     sleep(3)\n",
    "#     url = list_route[0]\n",
    "#     navegador.get(url)  #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "#     navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "# navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n",
    "# Coalesce o DataFrame para um único arquivo\n",
    "df_single_file = df.coalesce(1)\n",
    "# Salve o DataFrame coalesced como um único arquivo CSV\n",
    "df_single_file.write.csv(csv_caminho_arquivo, header=True, mode=\"overwrite\")\n",
    "Dessa forma o spark gera um csv particionado\n",
    "df.write.csv('pyspark_dataframe.csv', header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
