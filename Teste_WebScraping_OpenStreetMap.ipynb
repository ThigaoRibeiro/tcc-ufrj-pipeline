{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias para a raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIX_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSING = '/home/thiago/tcc_ufrj/PRE_PROCESSING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando o site Open Street Map e capturando as rotas pendentes e as rotas finalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "routes = site.findAll('tr')\n",
    "\n",
    "list_rotas_pendentes = []\n",
    "list_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for route in routes:\n",
    "    if route.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = route.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # list_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = route.find('a')        \n",
    "        lista_rotas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # list_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a telas para efetuar os downloads - Renomeando os arquivo adicionando o nome dos usuários - Movendo para a pasta PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navegador = webdriver.Chrome(service=servico)\n",
    "users = []\n",
    "for list_route in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = list_route[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    user_conteudo_da_pagina = navegador.page_source\n",
    "    site_user = BeautifulSoup(user_conteudo_da_pagina, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in site_user):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {list_route} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        users.append(nome_usuario)\n",
    "time.sleep(3)\n",
    "navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "files_to_rename = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for file_name in files_to_rename:\n",
    "        novo_nome = file_name.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, file_name), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for user, arquivo_para_renomear_gpx in zip(users, arquivos_para_renomear_gpx):\n",
    "    if os.listdir(DOWNLOADS):\n",
    "        caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)        \n",
    "        novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{user}.gpx\"        \n",
    "        caminho_novo = os.path.join(DOWNLOADS,novo_nome)        \n",
    "        #print(caminho_novo)\n",
    "        os.rename(caminho_antigo, caminho_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSING, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSING}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1ª Função. Responsável por fazer o download das rotas diretamente site, renomear os arquivos e os mover para a pasta de pré processamento - Essa execução deve ser executada de uma única vez, pois pode haver alguma falha no momento de renomear os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager\n",
    "# pip install BeautifulSoup4\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "import re\n",
    "import os\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import requests\n",
    "# options = Options()\n",
    "# options.add_argument('--headless') #--> Parâmetro adicional onde é possivel realizar o webscrapping sem abrir o navegador.\n",
    "# options.add_argument('window-size=400,800') #--> Parâmetro adicional onde é possivel escolher o tamanho da tela aberta no navegador. Nesse exemplo o tamanho 400x800 é como se estivesse aberto em um celular.\n",
    "# navegador = webdriver.Chrome(service=servico, options=options) #--> Aplicando as opções acima mencionadas no navegador.\n",
    "\n",
    "URL_OPEN_STREET_MAP_TRACES = 'https://www.openstreetmap.org/traces' #--> Página do OpenstreetMap onde estão localizadas as rotas para download.\n",
    "PREFIXO_URL_DOWNLOAD = 'https://www.openstreetmap.org' #--> Página do principal do OpenstreetMap. Esta variável será utilizada para montar a URL das páginas de download.\n",
    "DOWNLOADS = '/home/thiago/Downloads/'\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO'\n",
    "\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "navegador.get(URL_OPEN_STREET_MAP_TRACES)\n",
    "\n",
    "conteudo_da_pagina = navegador.page_source\n",
    "site = BeautifulSoup(conteudo_da_pagina, 'html.parser')\n",
    "rotas = site.findAll('tr')\n",
    "\n",
    "lista_rotas_pendentes = []\n",
    "lista_rotas_finalizadas = []\n",
    "lista_rotas = []\n",
    "\n",
    "for rota in rotas:\n",
    "    if rota.find('span', attrs={'class': 'text-danger'}):\n",
    "        rotas_pendentes = rota.find('span', attrs={'class': 'text-danger'})    \n",
    "        link_rotas_pendentes = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        # lista_rotas_pendentes.append([PREFIX_URL_DOWNLOAD+link_rotas_pendentes['href']])\n",
    "        print (f\"{rotas_pendentes.text}: {PREFIXO_URL_DOWNLOAD+link_rotas_pendentes['href']}\")\n",
    "\n",
    "    else:         \n",
    "        link_rotas_finalizadas = rota.find('a')        \n",
    "        lista_rotas.append([PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        # lista_rotas_finalizadas.append([PREFIX_URL_DOWNLOAD+link_rotas_finalizadas['href']])\n",
    "        print(f\"FINISHED: {PREFIXO_URL_DOWNLOAD+link_rotas_finalizadas['href']}\")\n",
    "time.sleep(3)\n",
    "navegador.close()\n",
    "\n",
    "#len(list_rotas_pendentes) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "#len(list_rotas_finalizadas) #--> Verificando a quantidade de registros na lista de rotas pendentes\n",
    "\n",
    "## Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "#navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "\n",
    "## Baixando os arquivos \n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "usuarios = []\n",
    "for lista_rota in lista_rotas:\n",
    "    time.sleep(3)\n",
    "    url = lista_rota[0]\n",
    "    navegador.get(url) #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "\n",
    "    conteudo_pagina_download = navegador.page_source\n",
    "    pagina_usuario = BeautifulSoup(conteudo_pagina_download, 'html.parser')\n",
    "\n",
    "    if any(td.find('span', attrs={'class': 'text-danger'}) for td in pagina_usuario):\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)        \n",
    "        print(f'Rota PENDENTE: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "\n",
    "    else:\n",
    "        tb_nome_usuario = navegador.find_element('xpath', '//*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td')\n",
    "        nome_usuario = tb_nome_usuario.text\n",
    "        nome_usuario = re.sub(r'\\s|\\.|\\(|\\)','_',nome_usuario)\n",
    "        print(f'Rota FINALIZADA: {lista_rota} Usuário: {nome_usuario}')\n",
    "        navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "        usuarios.append(nome_usuario)\n",
    "time.sleep(5)\n",
    "navegador.close()\n",
    "\n",
    "\n",
    "## Corrigindo o nome dos arquivos conforme seus usuários\n",
    "arquivos_para_renomear = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".crdownload\")]\n",
    "for arquivo_para_renomear in arquivos_para_renomear:\n",
    "        novo_nome = arquivo_para_renomear.replace(\".crdownload\", \"\")\n",
    "        os.rename(os.path.join(DOWNLOADS, arquivo_para_renomear), os.path.join(DOWNLOADS, novo_nome))\n",
    "\n",
    "arquivos_para_renomear_gpx = sorted([arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")], reverse=True)\n",
    "arquivos_para_renomear_gpx\n",
    "\n",
    "for usuario, arquivo_para_renomear_gpx in zip(usuarios, arquivos_para_renomear_gpx):        \n",
    "    caminho_antigo = os.path.join(DOWNLOADS, arquivo_para_renomear_gpx)\n",
    "    novo_nome = f\"{arquivo_para_renomear_gpx.replace('.gpx', '')}__{usuario}.gpx\"        \n",
    "    caminho_novo = os.path.join(DOWNLOADS,novo_nome)            \n",
    "    os.rename(caminho_antigo, caminho_novo)\n",
    "\n",
    "\n",
    "# Movendo os arquivos para a pasta PRE_PROCESSING\n",
    "time.sleep(3)\n",
    "arquivos_para_pre_processamento = [arquivo for arquivo in os.listdir(DOWNLOADS) if arquivo.endswith(\".gpx\")]\n",
    "for arquivo_para_pre_processamento in arquivos_para_pre_processamento:\n",
    "    caminho_origem = os.path.join(DOWNLOADS, arquivo_para_pre_processamento)\n",
    "    caminho_destino = os.path.join(PRE_PROCESSAMENTO, arquivo_para_pre_processamento)\n",
    "    try:\n",
    "        os.rename(caminho_origem,caminho_destino)\n",
    "        print(f\"Arquivo '{arquivo_para_pre_processamento}' movido para a pasta {PRE_PROCESSAMENTO}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao mover o arquivo: '{arquivo_para_pre_processamento}': {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ª Função - Lendo arquivos pasta de Pré Processamento - Convertendo os arquivos .gpx em .csv - Levando os arquivos .csv para a camada bronze do datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "### IMPORTAÇÃO DAS BIBLIOTECAS NECESSÁRIAS ###\n",
    "##############################################\n",
    "# pip install minio \n",
    "# pip install gpxpy\n",
    "# pip install pandas \n",
    "\n",
    "import gpxpy \n",
    "import gpxpy.gpx \n",
    "import pandas as pd \n",
    "import os \n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "##############################\n",
    "### DEFINIÇÃO DE VARIÁVEIS ### \n",
    "##############################\n",
    "PRE_PROCESSAMENTO = '/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO' \n",
    "CAMADA_BRONZE = 'bronze' \n",
    "\n",
    "##############################################\n",
    "### CRIANDO UMA INSTÂNCIA DO CLIENTE MINIO ###\n",
    "##############################################\n",
    "minioclient = Minio('localhost:9000', \n",
    "    access_key='minioadmin', \n",
    "    secret_key='minioadmin', \n",
    "    secure=False) \n",
    "\n",
    "###########################################################\n",
    "### CONVERTENDO OS ARQUIVOS COM A EXTENSÃO .GPX EM .CSV ###\n",
    "###########################################################\n",
    "arquivos_pre_processamento = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".gpx\")] \n",
    "for arquivo_pre_processamento in arquivos_pre_processamento: \n",
    "    caminho_arquivo = os.path.join(PRE_PROCESSAMENTO, arquivo_pre_processamento) \n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo_gpx: \n",
    "            gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "        info_rota = [] \n",
    "        for trilha in gpx.tracks: \n",
    "            for segmento in trilha.segments:\n",
    "                for ponto in segmento.points:\n",
    "                    info_rota.append({\n",
    "                        'latitude': ponto.latitude, \n",
    "                        'longitude': ponto.longitude, \n",
    "                        'elevacao' : ponto.elevation, \n",
    "                        'time_point' : ponto.time \n",
    "                    })\n",
    "        arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv') \n",
    "        info_rota_df = pd.DataFrame(info_rota) \n",
    "        info_rota_df.to_csv(f'{PRE_PROCESSAMENTO}/{arquivo_pre_processamento_csv}', index=False) \n",
    "        os.remove(caminho_arquivo) \n",
    "    except Exception as e: \n",
    "        print(f\"Erro ao converter o '{arquivo_pre_processamento}': {e}.\") \n",
    "        os.remove(caminho_arquivo)\n",
    "        print(f\"Excluindo o arquivo defeituoso: {arquivo_pre_processamento}\")\n",
    "        \n",
    "\n",
    "################################################################################################################\n",
    "### MOVENDO OS ARQUIVOS COM A EXTENSÃO .CSV DA PASTA PRE_PROCESSAMENTO PARA A PRIMEIRA CAMADA (BRONZE) NO MINIO ###\n",
    "################################################################################################################\n",
    "arquivos_para_datalake = [arquivo for arquivo in os.listdir(PRE_PROCESSAMENTO) if arquivo.endswith(\".csv\")] \n",
    "for nome_arquivo in arquivos_para_datalake: \n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSAMENTO, nome_arquivo) \n",
    "    if os.path.isfile(caminho_pre_proc): \n",
    "        try:\n",
    "            minioclient.fput_object(CAMADA_BRONZE, nome_arquivo, caminho_pre_proc) \n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\") \n",
    "            os.remove(caminho_pre_proc) \n",
    "        except S3Error as e: \n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/thiago/tcc_ufrj/PRE_PROCESSAMENTO/10086735__Routes_from_dragonpilot_2023_08_15__TOYOTA_RAV4_HYBRID_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "info_rota = [] #--> Lista que servirá de apoio para converter o arquivo .gpx em uma lista\n",
    "for trilha in gpx.tracks:\n",
    "    for segmento in trilha.segments:\n",
    "        for ponto in segmento.points:            \n",
    "            \n",
    "            latitude = ponto.latitude\n",
    "            longitude = ponto.longitude\n",
    "\n",
    "            address = location.raw['address']\n",
    "            city = address.get('city', '')\n",
    "            state = address.get('state', '')\n",
    "            country = address.get('country', '')\n",
    "\n",
    "            location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "            address = location.raw['address']\n",
    "            cidade = address.get('suburb')\n",
    "            estado = address.get('state')\n",
    "            pais = address.get('country_code')\n",
    "\n",
    "            info_rota.append({\n",
    "                'latitude': ponto.latitude,\n",
    "                'longitude': ponto.longitude,\n",
    "                'elevacao' : ponto.elevation,\n",
    "                'time_point' : ponto.time,\n",
    "                'cidade': cidade,\n",
    "                'estado': estado,\n",
    "                'pais': pais\n",
    "            })\n",
    "arquivo_pre_processamento_csv = arquivo_pre_processamento.replace('.gpx','.csv')\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "## os.remove(caminho_arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')\n",
    "\n",
    "estado = estado[-2:]\n",
    "pais = pais.upper()\n",
    "\n",
    "print(f\"Cidade: {cidade}\")\n",
    "print(f\"Estado (abreviado): {estado[-2:]}\")\n",
    "print(f\"País: {pais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADRAO_REGEX = r'(.*?)__'\n",
    "padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "id_rota = padrao_encontrado[0]\n",
    "nome_usuario = padrao_encontrado[-1]\n",
    "padrao_encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".csv\")]\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSAMENTO) if files.endswith(\".parquet\")]\n",
    "len(arquivos_para_datalake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos com a extensão .csv saem da pasta PRE_PROCESSING para a primeira camada (bronze) no MinIO\n",
    "#arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".csv\")]\n",
    "arquivos_para_datalake = [files for files in os.listdir(PRE_PROCESSING) if files.endswith(\".parquet\")]\n",
    "for nome_arquivo in arquivos_para_datalake:\n",
    "    caminho_pre_proc = os.path.join(PRE_PROCESSING, nome_arquivo)    \n",
    "    if os.path.isfile(caminho_pre_proc):\n",
    "        try:\n",
    "            minioclient.fput_object(BRONZE_LAYER, nome_arquivo, caminho_pre_proc)\n",
    "            print(f\"Arquivo {nome_arquivo} enviado com sucesso para o bucket.\")\n",
    "            os.remove(caminho_pre_proc) # --> Após o envio bem sucedido para o bucket o arquivo é excluído da pasta download\n",
    "        except S3Error as e:\n",
    "            print(f\"Erro ao enviar o arquivo: {nome_arquivo} -> Erro: {e}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRE_PROCESSING/9632214__Routes_from_sunnypilot_2023_08_19-dev__SUBARU_IMPREZA_LIMITED_2019__.gpx', 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = '9632229__Routes_from_sunnypilot_2023_08_19-dev__HYUNDAI_SANTA_FE_2019__.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_gpx = str(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arquivo_gpx, 'r', encoding='utf-8') as arquivo_gpx:\n",
    "    gpx = gpxpy.parse(arquivo_gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a quantidade de pontos (lat+lon+ele) em um arquivo arquivo '.gpx' podemos usar get\n",
    "# Documentação: https://pypi.org/project/gpxpy/\n",
    "gpx.get_track_points_no()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para retornar a faixa de altitude, a fim de se obter extremos de maior elevação e menor elevação no trajeto percorrido - os valores apresentados são em metros acima do nível do mar\n",
    "gpx.get_elevation_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não endendi para que isso serve\n",
    "gpx.get_uphill_downhill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o nome do criador da rota - Entretanto no nosso caso quando usamos esse comando temos uma informação generica - Foi necessário obter o nome do criador da rota com o WebScraping\n",
    "creator = gpx.creator\n",
    "creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para exibir o conteudo do arquivo .gpx em formato xml\n",
    "print(gpx.to_xml()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possivel verificar quantas rotas/trilhas nosso arquivo .gpx possui\n",
    "len(gpx.tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no nosso exemplo acima só temos 1 rota/trilha efetuada, podemos acessar por meio de indice no python, \n",
    "# Nesse caso se passa o valor [0] para ter uma precisão exata da rota em que estamos trabalhando\n",
    "gpx.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos acessar os segmentos da nossa rota/trilha\n",
    "gpx.tracks[0].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos acessar os pontos de dados individuais dentro do nosso gpx acessando a matriz de pontos. Aqui tambem podemo0s ver o nome das propriedades do arquivo como elevation e time\n",
    "gpx.tracks[0].segments[0].points[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui acessamos as tres camadas: Track - Segments e Point e o passamos para um array em forma de dicionário. Note que podemos acessar cada atributo. No meu caso estou pegando latitude, Longitude, Elevação e a hora de cada ponto (entenda-se como ponto Lat+Long+Ele)\n",
    "info_rota = []\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            info_rota.append({\n",
    "                'latitude': point.latitude,\n",
    "                'longitude': point.longitude,\n",
    "                'elevacao' : point.elevation,\n",
    "                'time_point' : point.time\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo somente os 3 primeiros resultados\n",
    "info_rota[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui podemos transformar essa informação em um dataframe com a biblioteca pandas\n",
    "info_rota_df = pd.DataFrame(info_rota)\n",
    "info_rota_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info_rota_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_csv('pandas_info_rota.csv', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui salvamos o pandas dataframe localmente\n",
    "info_rota_df.to_parquet('pd_parquet_info_rota.parquet', index=False)\n",
    "\n",
    "# <creator> contem o nome do cara que está se deslocando\n",
    "# existe uma <trkpt> acredito q seja um track point\n",
    "# <name> contem uma da e hora. Acredito que seja a hora do envio do arquivo gpx\n",
    "# <trkpt> é um bloco com lat - lon - internamente tem um <ele> de elevação e um <time> que acredito ser o horario que o cliente estava no ponto lat+long+ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3ª Função - Lendo o bucket e transformando os arquivos encontrados lá em DF Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "CAMADA_SILVER = 'silver'\n",
    "PADRAO_REGEX = r'(.*?)__'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "    try:\n",
    "\n",
    "        ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "        obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "        csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "        arquivo_csv = StringIO(csv_decod)\n",
    "        df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "        #### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "        df['time_point'] = pd.to_datetime(df['time_point'], format='%Y-%m-%d %H:%M:%S.%f%z', errors='coerce')\n",
    "        df['data'] = df['time_point'].dt.date\n",
    "        df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "        df = df.drop(columns=['time_point'])\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao alterar a data do arquivo: {nome_arquivo}. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "arquivos_rotas_gpx_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_BRONZE) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "\n",
    "    ### OBTENDO O ARQUIVO E O CONVERTENDO EM UM DF PANDAS ###\n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_BRONZE, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "    ### SEPARANDO A INFORMAÇÃO DE DATA E HORA EM 2 COLUNAS SEPARADAS ###\n",
    "    df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "    df['data'] = df['time_point'].dt.date\n",
    "    df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "    df = df.drop(columns=['time_point']) \n",
    "\n",
    "    ### USANDO O REGEX PARA PEGAR O ID DA RODA E O NOME DO USUÁRIO (DADOS PRESENTES NO NOME DO ARQUIVO) ###\n",
    "    nome_arquivo = arquivo_rotas_gpx_csv.object_name        \n",
    "    padrao_encontrado = re.findall(PADRAO_REGEX, nome_arquivo)\n",
    "    id_rota = padrao_encontrado[0]\n",
    "    nome_usuario = padrao_encontrado[-1]\n",
    "    num_df = len(df)\n",
    "    replic_id_rota = np.tile(id_rota, num_df)\n",
    "    replic_nome_usuario = np.tile(nome_usuario, num_df)\n",
    "    df['id_rota'] = replic_id_rota\n",
    "    df['nome_usuario'] = replic_nome_usuario\n",
    "    ordenacao_df = ['id_rota', 'nome_usuario', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "    df = df.reindex(columns=ordenacao_df)\n",
    "\n",
    "    try:\n",
    "        csv_bytes = df.to_csv(index=False).encode('utf-8') \n",
    "        csv_buffer = BytesIO(csv_bytes)\n",
    "        minioclient.put_object(\n",
    "                            CAMADA_SILVER,\n",
    "                            nome_arquivo,\n",
    "                            data=csv_buffer,\n",
    "                            length=len(csv_bytes),\n",
    "                            content_type='application/csv')\n",
    "\n",
    "        #minioclient.remove_object(CAMADA_BRONZE, nome_arquivo)        \n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"Erro ao enviar o arquivo: {nome_arquivo} para a [camada silver]. Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destino_csv_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_rota_csv = minioclient.get_object(BRONZE_LAYER, '9781413__Routes_from_dragonpilot_2023_07_05__TOYOTA_COROLLA_TSS2_2019__.csv')\n",
    "rota_csv = blob_rota_csv.data\n",
    "rota_csv = rota_csv.decode(\"ISO-8859-1\")\n",
    "pre_df = StringIO(rota_csv)\n",
    "df = pd.read_csv(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_point'] = pd.to_datetime(df['time_point'])\n",
    "df['data'] = df['time_point'].dt.date\n",
    "df['hora'] = df['time_point'].dt.strftime('%H:%M:%S')\n",
    "df = df.drop(columns=['time_point'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text = \"9781892__Routes_from_sunnypilot_0_9_3_1-release__HONDA_ACCORD_2018__.gpx\"\n",
    "\n",
    "# Definindo o padrão de regex\n",
    "pattern = r'(.*?)__'\n",
    "\n",
    "# Encontrando todas as correspondências no texto\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Extraindo o nome do carro\n",
    "username = matches[-1]\n",
    "id = matches[0]\n",
    "\n",
    "print(f'Id: {id} - username: {username}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = len(df)\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_id = np.tile(id, num_df)\n",
    "repeated_user = np.tile(username, num_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = repeated_id\n",
    "df['username'] = repeated_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "desired_order = ['id', 'username', 'latitude', 'longitude', 'elevacao', 'data', 'hora']\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('arquivo.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ª Função - Lendo o bucket Silver e Escrevendo os arquivos no banco de dados Postgres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2\n",
    "import psycopg2\n",
    "import os\n",
    "from minio import Minio\n",
    "import io\n",
    "\n",
    "CAMADA_SILVER = 'silver'\n",
    "\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)\n",
    "\n",
    "db_config = {\n",
    "'host': 'localhost',\n",
    "'database': 'gold-saint',\n",
    "'user': 'postgres',\n",
    "'password': 'postgres',\n",
    "}\n",
    "\n",
    "copy_sql = \"\"\"\n",
    "    COPY tb_gpx_full (id_rota, nome_usuario, latitude, longitude, elevacao, data_rota, hora_rota)\n",
    "    FROM stdin WITH CSV HEADER DELIMITER as ','\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "if not arquivos_rotas_gpx_csv:\n",
    "    print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "else:\n",
    "    print(f\"Existem {len(arquivos_rotas_gpx_csv)} arquivos no Bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Lista todos os arquivos na camada \"silver\" do Minio que têm extensão .csv\n",
    "    arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "    \n",
    "    # Verifica se há arquivos no bucket antes de continuar\n",
    "    if not arquivos_rotas_gpx_csv:\n",
    "        print(\"Não existem arquivos CSV no bucket. Nenhuma carga de dados será executada.\")\n",
    "\n",
    "    else:\n",
    "        # Conexão com o banco de dados PostgreSQL\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Itera sobre cada arquivo CSV encontrado no Minio\n",
    "        for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:\n",
    "            # Obtém o objeto do arquivo CSV do Minio  \n",
    "            obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)            \n",
    "\n",
    "            # Decodifica os dados do arquivo CSV de bytes para string\n",
    "            csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string            \n",
    "\n",
    "            # Usa io.StringIO para criar um objeto de arquivo legível a partir da string CSV\n",
    "            with io.StringIO(csv_decod) as file:        \n",
    "\n",
    "                # Executa o comando COPY para inserir os dados no banco de dados PostgreSQL\n",
    "                cursor.copy_expert(sql=copy_sql, file=file)\n",
    "\n",
    "            # Commit para salvar as alterações no banco de dados    \n",
    "            conn.commit()        \n",
    "\n",
    "            # Remove o arquivo do bucket \"silver\" no Minio após ser processado\n",
    "            # minioclient.remove_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name) \n",
    "\n",
    "        # Fecha a conexão com o banco de dados PostgreSQL\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    # Em caso de erro, imprime a mensagem de erro\n",
    "    print(f\"Erro: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5ª Função - Enriquecendo o DF com informação de pais - estado e cidade - Carregando o DF Enriquecido na camada GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install minio\n",
    "# pip install pandas\n",
    "# pip install numpy\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "CAMADA_BRONZE = 'bronze'\n",
    "CAMADA_SILVER = 'silver'\n",
    "CAMADA_GOLD = 'gold'\n",
    "PADRAO_REGEX = r'(.*?)__'\n",
    "\n",
    "minioclient = Minio('localhost:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_locations_equal(location1, location2):\n",
    "    return location1 == location2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:    \n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "\n",
    "    batch_size = 1000\n",
    "    batch_list = [df[i:i+batch_size].copy() for i in range(0, len(df), batch_size)]\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\", timeout=10)\n",
    "    processed_batches = []  # Inicialize a lista de lotes processados\n",
    "    last_locations = {}\n",
    "\n",
    "\n",
    "    for batch_df in batch_list:\n",
    "        # Obtenha a primeira e a última linha do lote\n",
    "        first_row = batch_df.iloc[0]\n",
    "        last_row = batch_df.iloc[-1]\n",
    "\n",
    "        first_location_str = f\"{first_row['latitude']},{first_row['longitude']}\"\n",
    "        last_location_str = f\"{last_row['latitude']},{last_row['longitude']}\"\n",
    "\n",
    "        # Verifique se a primeira e a última localização são iguais à última localização verificada\n",
    "        if are_locations_equal(first_location_str, last_location_str) and are_locations_equal(first_location_str, last_location):\n",
    "            # Se forem iguais, não é necessário consultar o serviço novamente\n",
    "            location = last_location\n",
    "        else:\n",
    "            # Se forem diferentes, consulte o serviço de geocodificação para a última localização\n",
    "            location = geolocator.reverse(last_location_str)\n",
    "            last_location = location\n",
    "\n",
    "        address = location.raw['address']\n",
    "        cidade = address.get('county')\n",
    "        estado = address.get('ISO3166-2-lvl4')\n",
    "        pais = address.get('country_code')\n",
    "        \n",
    "        estado = estado[-2:]\n",
    "        pais = pais.upper()\n",
    "        \n",
    "        df.loc[:, 'cidade'] = cidade\n",
    "        df.loc[:, 'estado'] = estado\n",
    "        df.loc[:, 'pais'] = pais\n",
    "\n",
    "    # Converta o DataFrame enriquecido de volta para CSV\n",
    "    enriched_csv = df.to_csv(index=False)\n",
    "    enriched_csv_bytes = enriched_csv.encode('utf-8')\n",
    "\n",
    "    # Crie um buffer de bytes\n",
    "    enriched_csv_buffer = BytesIO(enriched_csv_bytes)\n",
    "\n",
    "    minioclient.put_object(\n",
    "        CAMADA_GOLD,\n",
    "        arquivo_rotas_gpx_csv.object_name,  # Use o mesmo nome de arquivo\n",
    "        data=enriched_csv_buffer,\n",
    "        length=len(enriched_csv_bytes),\n",
    "        content_type='application/csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos_rotas_gpx_csv = [arquivo_gpx for arquivo_gpx in minioclient.list_objects(CAMADA_SILVER) if arquivo_gpx.object_name.endswith(\".csv\")]\n",
    "for arquivo_rotas_gpx_csv in arquivos_rotas_gpx_csv:    \n",
    "    obj_rota_csv = minioclient.get_object(CAMADA_SILVER, arquivo_rotas_gpx_csv.object_name)        \n",
    "    csv_decod = obj_rota_csv.data.decode('utf-8')  # Convertendo bytes para string    \n",
    "    arquivo_csv = StringIO(csv_decod)\n",
    "    df = pd.read_csv(arquivo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id_rota</th>\n",
       "      <th>nome_usuario</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevacao</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.580081</td>\n",
       "      <td>-95.647901</td>\n",
       "      <td>-5.960</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.580081</td>\n",
       "      <td>-95.647901</td>\n",
       "      <td>-5.955</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.580081</td>\n",
       "      <td>-95.647901</td>\n",
       "      <td>-5.960</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.580081</td>\n",
       "      <td>-95.647901</td>\n",
       "      <td>-5.972</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.580082</td>\n",
       "      <td>-95.647901</td>\n",
       "      <td>-5.965</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5996</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.638313</td>\n",
       "      <td>-95.704909</td>\n",
       "      <td>1.788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5997</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.638339</td>\n",
       "      <td>-95.704921</td>\n",
       "      <td>1.760</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:25:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5998</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.638364</td>\n",
       "      <td>-95.704933</td>\n",
       "      <td>1.738</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:25:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5999</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.638390</td>\n",
       "      <td>-95.704944</td>\n",
       "      <td>1.701</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:25:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>6000</td>\n",
       "      <td>10097302</td>\n",
       "      <td>TOYOTA_HIGHLANDER_HYBRID_2020</td>\n",
       "      <td>29.638416</td>\n",
       "      <td>-95.704956</td>\n",
       "      <td>1.653</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>22:25:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   id_rota                   nome_usuario   latitude  longitude  \\\n",
       "0         1  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.580081 -95.647901   \n",
       "1         2  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.580081 -95.647901   \n",
       "2         3  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.580081 -95.647901   \n",
       "3         4  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.580081 -95.647901   \n",
       "4         5  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.580082 -95.647901   \n",
       "...     ...       ...                            ...        ...        ...   \n",
       "5995   5996  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.638313 -95.704909   \n",
       "5996   5997  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.638339 -95.704921   \n",
       "5997   5998  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.638364 -95.704933   \n",
       "5998   5999  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.638390 -95.704944   \n",
       "5999   6000  10097302  TOYOTA_HIGHLANDER_HYBRID_2020  29.638416 -95.704956   \n",
       "\n",
       "      elevacao        data      hora  \n",
       "0       -5.960  2023-09-10  22:15:44  \n",
       "1       -5.955  2023-09-10  22:15:44  \n",
       "2       -5.960  2023-09-10  22:15:44  \n",
       "3       -5.972  2023-09-10  22:15:44  \n",
       "4       -5.965  2023-09-10  22:15:44  \n",
       "...        ...         ...       ...  \n",
       "5995     1.788         NaN       NaN  \n",
       "5996     1.760  2023-09-10  22:25:44  \n",
       "5997     1.738  2023-09-10  22:25:44  \n",
       "5998     1.701  2023-09-10  22:25:44  \n",
       "5999     1.653  2023-09-10  22:25:44  \n",
       "\n",
       "[6000 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"25.08258016168485\"\n",
    "Longitude = \"121.37994126205\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amenity': '第一商業銀行',\n",
       " 'house_number': '498',\n",
       " 'road': '中山路',\n",
       " 'neighbourhood': '湖南里',\n",
       " 'suburb': '林口區',\n",
       " 'city': '新北市',\n",
       " 'ISO3166-2-lvl4': 'TW-NWT',\n",
       " 'postcode': '24446',\n",
       " 'country': '臺灣',\n",
       " 'country_code': 'tw'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = location.raw['address']\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')\n",
    "\n",
    "estado = estado[-2:]\n",
    "pais = pais.upper()\n",
    "\n",
    "print(f\"Cidade: {cidade}\")\n",
    "print(f\"Estado (abreviado): {estado[-2:]}\")\n",
    "print(f\"País: {pais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "cidade = address.get('county')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o Pandas e o Spark para leitura dos dados no Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = location.raw['address']\n",
    "city = address.get('city', '')\n",
    "state = address.get('state', '')\n",
    "country = address.get('country', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "Latitude = \"45.24559097710776\"\n",
    "Longitude = \"-122.79781984274484\"\n",
    "location = geolocator.reverse(f'{Latitude},{Longitude}') \n",
    "print(location)\n",
    "\n",
    "address = location.raw['address']\n",
    "cidade = address.get('suburb')\n",
    "estado = address.get('ISO3166-2-lvl4')\n",
    "pais = address.get('country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cidade:\", cidade)\n",
    "print(\"Estado (abreviado):\", estado)\n",
    "print(\"País:\", pais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'gold-saint',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM tb_gpx_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_config)\n",
    "\n",
    "df_pandas = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_info_localizacao(df):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    latitudes = df['latitude'].astype(str)\n",
    "    longitudes = df['longitude'].astype(str)\n",
    "\n",
    "    def obter_localizacao(latitude, longitude):\n",
    "        location = geolocator.reverse(f'{latitude},{longitude}')\n",
    "        address = location.raw['address']\n",
    "        cidade = address.get('suburb')\n",
    "        estado = address.get('state')\n",
    "        pais = address.get('country_code')\n",
    "        return cidade, estado, pais\n",
    "    df[['cidade', 'estado', 'pais']] = zip(*[obter_localizacao(lat, lon) for lat, lon in zip(latitudes, longitudes)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultante = obter_info_localizacao(df_pandas)\n",
    "df_resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos não mais usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta download para a pasta DATALAKE_STAGE\n",
    "\n",
    "# files_to_move = [files for files in os.listdir(DOWNLOADS) if files.endswith(\".gpx\")]\n",
    "# for nome_arquivos in files_to_move:\n",
    "#     origin_path = os.path.join(DOWNLOADS, nome_arquivos)\n",
    "#     destiny_path = os.path.join(DATALAKE_STAGE, nome_arquivos)\n",
    "#     os.rename(origin_path, destiny_path)\n",
    "#     print(f\"Arquivo {nome_arquivos} movido para {destiny_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aqui os arquivos saem da pasta DATALAKE_STAGE para o bucket MinIO\n",
    "\n",
    "# for item in os.listdir(DATALAKE_STAGE):\n",
    "#     caminho_pre_proc = os.path.join(DATALAKE_STAGE, item)\n",
    "#     print(caminho_pre_proc)\n",
    "# \n",
    "#     if os.path.isfile(caminho_pre_proc):\n",
    "#         try:\n",
    "#             minioclient.fput_object(DATA_LAKE, item, caminho_pre_proc)\n",
    "#             print(f\"Arquivo {item} enviado com sucesso para o bucket.\")\n",
    "#         except S3Error as err:\n",
    "#             print(f\"Erro ao enviar o arquivo {item}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DADOS PARA INSERIR NA TABELA DE CONTROLE USANDO O BEAUTIFULSOAP ## #\n",
    "# navegador = requests.get('https://www.openstreetmap.org/user/sunnypilot/traces/9255974')\n",
    "# site = BeautifulSoup(navegador.text, 'html.parser')\n",
    "# data_trace = site.find('div', attrs={'class': 'content-body'})\n",
    "# table_trace = data_trace.find('table')\n",
    "# \n",
    "# filename_row = table_trace.find('th', string='Filename:').parent\n",
    "# owner_row = table_trace.find('th', string='Owner:').parent\n",
    "# uploaded_row = table_trace.find('th', string='Uploaded:').parent\n",
    "# \n",
    "# filename = filename_row.find('td').text.strip().replace('(download)','').strip()\n",
    "# owner = owner_row.find('td').text.strip()\n",
    "# uploaded = uploaded_row.find('td').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ESTE TRECHO TEM A FINALIDADE DE BAIXAR OS ARQUIVOS ## #\n",
    "#list_rotas_finalizadas\n",
    "#list_rotas_pendentes\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[6]/td - finalizado\n",
    "# //*[@id=\"content\"]/div[2]/div/span = PENDENTE\n",
    "# //*[@id=\"content\"]/div[2]/div/table/tbody/tr[4]/td - pendente\n",
    "\n",
    "# ## Trecho descontinuado -- Quando usa [requests.get] estamos usando o BeautifulSoup - e quando usamos só o [.get] estamos usando o selenium\n",
    "# navegador = webdriver.Chrome(service=servico)\n",
    "# for list_route in lista_rotas:\n",
    "#     sleep(3)\n",
    "#     url = list_route[0]\n",
    "#     navegador.get(url)  #--> Exemplo onde usamos o Selenium somente com o [.get]\n",
    "#     navegador.find_element('xpath','//*[@id=\"content\"]/div[2]/div/table/tbody/tr[1]/td/a').click()\n",
    "# navegador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Criando as variáveis que serão utilizadas no Spark\n",
    "appname = 'tcc-project'\n",
    "master = 'local'\n",
    "# Criando a sessão Spark\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(appname)\\\n",
    "    .master(master)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n",
    "# Coalesce o DataFrame para um único arquivo\n",
    "df_single_file = df.coalesce(1)\n",
    "# Salve o DataFrame coalesced como um único arquivo CSV\n",
    "df_single_file.write.csv(csv_caminho_arquivo, header=True, mode=\"overwrite\")\n",
    "Dessa forma o spark gera um csv particionado\n",
    "df.write.csv('pyspark_dataframe.csv', header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
